"""
=============================================================================
ANALISIS 2: AN√ÅLISIS DE DATOS CON LIBRER√çAS PROFESIONALES
=============================================================================

Autor: Curso de Introducci√≥n a Programaci√≥n
Descripci√≥n: An√°lisis de datos CSV usando librer√≠as profesionales de Python
             (pandas, numpy, scipy, matplotlib, seaborn, scikit-learn)

Niveles:
  1. Estad√≠stica B√°sica con pandas y numpy
  2. Estad√≠stica Avanzada con scipy
  3. Ciencia de Datos con scikit-learn y visualizaciones

Librer√≠as utilizadas:
  - pandas: Manipulaci√≥n y an√°lisis de datos
  - numpy: Operaciones num√©ricas y arrays
  - scipy: Estad√≠stica avanzada
  - matplotlib: Visualizaciones b√°sicas
  - seaborn: Visualizaciones estad√≠sticas avanzadas
  - scikit-learn: Machine learning y an√°lisis predictivo

INSTALACI√ìN DE DEPENDENCIAS:
----------------------------
Si encuentras errores de compatibilidad con NumPy 2.x, ejecuta:

  pip install numpy<2.0
  pip install --upgrade pandas scipy matplotlib seaborn scikit-learn

O instala todas las dependencias con versiones compatibles:

  pip install numpy==1.26.4 pandas==2.2.3 scipy==1.15.2 matplotlib==3.9.2 seaborn==0.13.2 scikit-learn==1.5.1

NOTA: Este script est√° dise√±ado para ense√±ar el uso de librer√≠as profesionales
      en contraste con el enfoque manual del script 08_analisis_csv.py
"""

import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n de visualizaciones
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")


# =============================================================================
# FUNCIONES DE CARGA DE DATOS
# =============================================================================

def cargar_datos(archivo="./sample/BMW sales data (2010-2024) (1).csv"):
    """
    Carga datos CSV usando pandas.

    Args:
        archivo: Ruta del archivo CSV

    Returns:
        DataFrame de pandas con los datos
    """
    try:
        # Intentar diferentes encodings
        for encoding in ['utf-8-sig', 'utf-8', 'latin-1', 'iso-8859-1']:
            try:
                df = pd.read_csv(archivo, encoding=encoding)
                print(f"‚úÖ Archivo cargado exitosamente con encoding: {encoding}")
                print(f"üìä Dimensiones: {df.shape[0]:,} filas √ó {df.shape[1]} columnas")
                return df
            except UnicodeDecodeError:
                continue
        
        # Si ning√∫n encoding funciona
        df = pd.read_csv(archivo)
        return df
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo '{archivo}'")
        return None
    except Exception as e:
        print(f"‚ùå Error al cargar el archivo: {e}")
        return None


def mostrar_info_dataset(df):
    """Muestra informaci√≥n general del dataset."""
    print("\n" + "="*70)
    print("üìã INFORMACI√ìN GENERAL DEL DATASET")
    print("="*70)
    
    print(f"\nüìè Dimensiones: {df.shape[0]:,} filas √ó {df.shape[1]} columnas")
    
    print("\nüìä Columnas y tipos de datos:")
    print(df.dtypes)
    
    print("\nüîç Primeras 5 filas:")
    print(df.head())
    
    print("\nüìà Estad√≠sticas descriptivas:")
    print(df.describe())
    
    print("\n‚ùì Valores nulos:")
    print(df.isnull().sum())
    
    print("\nüíæ Uso de memoria:")
    print(f"{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")


# =============================================================================
# NIVEL 1: ESTAD√çSTICA B√ÅSICA CON PANDAS Y NUMPY
# =============================================================================

def estadistica_basica_pandas(df):
    """An√°lisis estad√≠stico b√°sico usando pandas y numpy."""
    print("\n" + "="*70)
    print("NIVEL 1: ESTAD√çSTICA B√ÅSICA - Pandas & NumPy")
    print("="*70)

    print("\nüìÅ Archivo: BMW sales data (2010-2024) (1).csv")
    print("üìã Descripci√≥n: An√°lisis estad√≠stico b√°sico usando pandas para")
    print("               manipulaci√≥n de datos y numpy para c√°lculos num√©ricos.")

    # 1. An√°lisis de frecuencias con value_counts()
    print("\n" + "‚îÄ"*70)
    print("üìä AN√ÅLISIS DE FRECUENCIAS - value_counts()")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Identificar los modelos m√°s populares en el dataset")
    print("üîß Algoritmo: Cuenta la aparici√≥n de cada valor √∫nico en la columna")
    print("üìà Valores posibles: Enteros positivos (n√∫mero de ocurrencias)")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ Valores altos = Modelos m√°s vendidos/populares")
    print("   ‚Ä¢ Distribuci√≥n uniforme = Ventas equilibradas entre modelos")
    print("   ‚Ä¢ Distribuci√≥n desigual = Algunos modelos dominan el mercado")
    print()

    print("--- Top 10 Modelos M√°s Vendidos (usando value_counts) ---")
    top_modelos = df['Model'].value_counts().head(10)
    for modelo, cantidad in top_modelos.items():
        print(f"  {modelo}: {cantidad:,} ventas")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    max_ventas = top_modelos.max()
    min_ventas = top_modelos.min()
    diferencia = max_ventas - min_ventas
    print(f"   ‚Ä¢ Modelo m√°s vendido: {top_modelos.index[0]} ({max_ventas:,} ventas)")
    print(f"   ‚Ä¢ Diferencia con el 10¬∞: {diferencia:,} ventas ({diferencia/max_ventas*100:.1f}%)")
    if diferencia / max_ventas < 0.05:
        print("   ‚Ä¢ Conclusi√≥n: Ventas muy equilibradas entre modelos")
    else:
        print("   ‚Ä¢ Conclusi√≥n: Hay modelos claramente m√°s populares")

    # 2. Estad√≠sticas descriptivas con describe()
    print("\n" + "‚îÄ"*70)
    print("üìä ESTAD√çSTICAS DESCRIPTIVAS - describe()")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Obtener un resumen estad√≠stico completo de los precios")
    print("üîß Algoritmo: Calcula medidas de tendencia central y dispersi√≥n")
    print("üìà Valores posibles:")
    print("   ‚Ä¢ Promedio: Suma de valores / cantidad (sensible a outliers)")
    print("   ‚Ä¢ Mediana: Valor central (robusto a outliers)")
    print("   ‚Ä¢ Desv. Est√°ndar: Dispersi√≥n promedio respecto a la media")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ Promedio ‚âà Mediana ‚Üí Distribuci√≥n sim√©trica")
    print("   ‚Ä¢ Promedio > Mediana ‚Üí Distribuci√≥n sesgada a la derecha")
    print("   ‚Ä¢ Desv. Est√°ndar alta ‚Üí Precios muy variables")
    print()

    print("--- Estad√≠sticas de Precios (USD) ---")
    precio_stats = df['Price_USD'].describe()
    promedio = precio_stats['mean']
    mediana = precio_stats['50%']
    desv_std = precio_stats['std']
    print(f"  Promedio: ${promedio:,.2f}")
    print(f"  Mediana (50%): ${mediana:,.2f}")
    print(f"  Desv. Est√°ndar: ${desv_std:,.2f}")
    print(f"  M√≠nimo: ${precio_stats['min']:,.2f}")
    print(f"  M√°ximo: ${precio_stats['max']:,.2f}")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    diferencia_prom_med = abs(promedio - mediana)
    coef_variacion = (desv_std / promedio) * 100
    print(f"   ‚Ä¢ Diferencia Promedio-Mediana: ${diferencia_prom_med:,.2f}")
    if diferencia_prom_med / promedio < 0.01:
        print("   ‚Ä¢ Distribuci√≥n: Aproximadamente sim√©trica")
    elif promedio > mediana:
        print("   ‚Ä¢ Distribuci√≥n: Sesgada a la derecha (m√°s valores altos)")
    else:
        print("   ‚Ä¢ Distribuci√≥n: Sesgada a la izquierda (m√°s valores bajos)")
    print(f"   ‚Ä¢ Coeficiente de Variaci√≥n: {coef_variacion:.1f}%")
    if coef_variacion < 15:
        print("   ‚Ä¢ Variabilidad: Baja (precios homog√©neos)")
    elif coef_variacion < 30:
        print("   ‚Ä¢ Variabilidad: Moderada")
    else:
        print("   ‚Ä¢ Variabilidad: Alta (precios muy dispersos)")
    
    # 3. Agrupaciones con groupby()
    print("\n--- Volumen Total de Ventas por Regi√≥n (usando groupby) ---")
    ventas_region = df.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False)
    for region, volumen in ventas_region.items():
        print(f"  {region}: {volumen:,.0f} unidades")
    
    # 4. Operaciones con numpy
    print("\n--- An√°lisis con NumPy ---")
    precios_array = df['Price_USD'].values
    print(f"  Media (np.mean): ${np.mean(precios_array):,.2f}")
    print(f"  Mediana (np.median): ${np.median(precios_array):,.2f}")
    print(f"  Percentil 25: ${np.percentile(precios_array, 25):,.2f}")
    print(f"  Percentil 75: ${np.percentile(precios_array, 75):,.2f}")
    print(f"  Percentil 95: ${np.percentile(precios_array, 95):,.2f}")
    
    # 5. Filtrado avanzado con pandas
    print("\n--- Veh√≠culos de Lujo (Precio > $100,000) ---")
    lujo = df[df['Price_USD'] > 100000]
    print(f"  Total: {len(lujo):,} veh√≠culos ({len(lujo)/len(df)*100:.1f}%)")
    print(f"  Precio promedio: ${lujo['Price_USD'].mean():,.2f}")
    
    # 6. Crosstab para an√°lisis cruzado
    print("\n--- Distribuci√≥n: Tipo de Combustible √ó Transmisi√≥n ---")
    crosstab = pd.crosstab(df['Fuel_Type'], df['Transmission'])
    print(crosstab)

    # 7. Correlaci√≥n b√°sica
    print("\n" + "‚îÄ"*70)
    print("üìä MATRIZ DE CORRELACI√ìN - Pearson")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Medir la relaci√≥n lineal entre variables num√©ricas")
    print("üîß Algoritmo: Coeficiente de correlaci√≥n de Pearson (r)")
    print("üìà Valores posibles: -1 a +1")
    print("   ‚Ä¢ r = +1: Correlaci√≥n positiva perfecta")
    print("   ‚Ä¢ r = 0: Sin correlaci√≥n lineal")
    print("   ‚Ä¢ r = -1: Correlaci√≥n negativa perfecta")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ |r| > 0.7: Correlaci√≥n fuerte")
    print("   ‚Ä¢ 0.3 < |r| < 0.7: Correlaci√≥n moderada")
    print("   ‚Ä¢ |r| < 0.3: Correlaci√≥n d√©bil")
    print()

    print("--- Matriz de Correlaci√≥n (Variables Num√©ricas) ---")
    columnas_numericas = ['Price_USD', 'Sales_Volume', 'Mileage_KM', 'Engine_Size_L']
    correlacion = df[columnas_numericas].corr()
    print(correlacion.round(4))

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    # Encontrar las correlaciones m√°s fuertes (excluyendo diagonal)
    corr_abs = correlacion.abs()
    np.fill_diagonal(corr_abs.values, 0)
    max_corr = corr_abs.max().max()
    if max_corr > 0.7:
        print(f"   ‚Ä¢ Correlaci√≥n m√°xima: {max_corr:.4f} (FUERTE)")
        print("   ‚Ä¢ Hay variables con relaci√≥n lineal fuerte")
    elif max_corr > 0.3:
        print(f"   ‚Ä¢ Correlaci√≥n m√°xima: {max_corr:.4f} (MODERADA)")
        print("   ‚Ä¢ Hay variables con relaci√≥n lineal moderada")
    else:
        print(f"   ‚Ä¢ Correlaci√≥n m√°xima: {max_corr:.4f} (D√âBIL)")
        print("   ‚Ä¢ Las variables son mayormente independientes")
        print("   ‚Ä¢ No hay relaciones lineales fuertes entre variables")


# =============================================================================
# NIVEL 2: ESTAD√çSTICA AVANZADA CON SCIPY
# =============================================================================

def estadistica_avanzada_scipy(df):
    """An√°lisis estad√≠stico avanzado usando scipy."""
    print("\n" + "="*70)
    print("NIVEL 2: ESTAD√çSTICA AVANZADA - SciPy")
    print("="*70)
    
    print("\nüìÅ Archivo: BMW sales data (2010-2024) (1).csv")
    print("üìã Descripci√≥n: An√°lisis estad√≠stico avanzado usando scipy para")
    print("               pruebas de hip√≥tesis, distribuciones y estad√≠stica inferencial.")
    
    # 1. Test de normalidad (Shapiro-Wilk)
    print("\n" + "‚îÄ"*70)
    print("üìä TEST DE NORMALIDAD - Shapiro-Wilk")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Determinar si los datos siguen una distribuci√≥n normal")
    print("üîß Algoritmo: Compara la distribuci√≥n observada con la normal te√≥rica")
    print("üìà Valores posibles:")
    print("   ‚Ä¢ Estad√≠stico W: 0 a 1 (1 = perfectamente normal)")
    print("   ‚Ä¢ P-valor: 0 a 1")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ p > 0.05: NO rechazamos normalidad (datos probablemente normales)")
    print("   ‚Ä¢ p ‚â§ 0.05: Rechazamos normalidad (datos NO normales)")
    print("   ‚Ä¢ Importante para decidir qu√© pruebas estad√≠sticas usar")
    print()

    print("--- Test de Normalidad (Shapiro-Wilk) ---")
    muestra_precios = df['Price_USD'].sample(min(5000, len(df)), random_state=42)
    statistic, p_value = stats.shapiro(muestra_precios)
    print(f"  Estad√≠stico W: {statistic:.6f}")
    print(f"  P-valor: {p_value:.6f}")
    if p_value > 0.05:
        print("  ‚úÖ Los precios siguen una distribuci√≥n normal (p > 0.05)")
    else:
        print("  ‚ùå Los precios NO siguen una distribuci√≥n normal (p ‚â§ 0.05)")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    print(f"   ‚Ä¢ Estad√≠stico W = {statistic:.6f}")
    if statistic > 0.99:
        print("   ‚Ä¢ Muy cercano a 1: Distribuci√≥n casi perfectamente normal")
    elif statistic > 0.95:
        print("   ‚Ä¢ Cercano a 1: Distribuci√≥n aproximadamente normal")
    else:
        print("   ‚Ä¢ Alejado de 1: Distribuci√≥n claramente no normal")

    if p_value > 0.05:
        print("   ‚Ä¢ Recomendaci√≥n: Usar pruebas param√©tricas (t-test, ANOVA)")
    else:
        print("   ‚Ä¢ Recomendaci√≥n: Usar pruebas no param√©tricas (Mann-Whitney, Kruskal-Wallis)")

    # 2. Test de Kruskal-Wallis (comparaci√≥n de m√∫ltiples grupos)
    print("\n" + "‚îÄ"*70)
    print("üìä TEST DE KRUSKAL-WALLIS - Comparaci√≥n de Grupos")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Comparar precios entre diferentes tipos de combustible")
    print("üîß Algoritmo: Versi√≥n no param√©trica de ANOVA (no requiere normalidad)")
    print("   ‚Ä¢ Compara las medianas de 3+ grupos independientes")
    print("   ‚Ä¢ Basado en rangos, no en valores absolutos")
    print("üìà Valores posibles:")
    print("   ‚Ä¢ H-estad√≠stico: ‚â• 0 (valores altos = m√°s diferencias)")
    print("   ‚Ä¢ P-valor: 0 a 1")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ p < 0.05: Al menos un grupo es diferente")
    print("   ‚Ä¢ p ‚â• 0.05: No hay diferencias significativas entre grupos")
    print()

    print("--- Test de Kruskal-Wallis: Precios por Tipo de Combustible ---")
    grupos_combustible = [df[df['Fuel_Type'] == fuel]['Price_USD'].values
                          for fuel in df['Fuel_Type'].unique()]
    h_stat, p_value = stats.kruskal(*grupos_combustible)
    print(f"  H-estad√≠stico: {h_stat:.4f}")
    print(f"  P-valor: {p_value:.6f}")
    print(f"  Grupos comparados: {len(grupos_combustible)} tipos de combustible")
    if p_value < 0.05:
        print("  ‚úÖ Hay diferencias significativas entre grupos (p < 0.05)")
    else:
        print("  ‚ùå No hay diferencias significativas entre grupos (p ‚â• 0.05)")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    if p_value < 0.05:
        print("   ‚Ä¢ Los precios var√≠an significativamente seg√∫n el combustible")
        print("   ‚Ä¢ Recomendaci√≥n: Analizar qu√© tipo es m√°s caro/barato")
    else:
        print("   ‚Ä¢ Los precios son similares entre tipos de combustible")
        print("   ‚Ä¢ El tipo de combustible NO afecta significativamente el precio")
    
    # 3. Intervalos de confianza
    print("\n--- Intervalo de Confianza 95% para Precio Promedio ---")
    precios = df['Price_USD'].values
    confidence_interval = stats.t.interval(
        confidence=0.95,
        df=len(precios)-1,
        loc=np.mean(precios),
        scale=stats.sem(precios)
    )
    print(f"  IC 95%: [${confidence_interval[0]:,.2f}, ${confidence_interval[1]:,.2f}]")
    print(f"  Media: ${np.mean(precios):,.2f}")
    
    # 4. Coeficiente de asimetr√≠a y curtosis
    print("\n--- Asimetr√≠a y Curtosis de Precios ---")
    skewness = stats.skew(precios)
    kurt = stats.kurtosis(precios)
    print(f"  Asimetr√≠a (Skewness): {skewness:.4f}")
    if abs(skewness) < 0.5:
        print("    ‚Üí Distribuci√≥n aproximadamente sim√©trica")
    elif skewness > 0:
        print("    ‚Üí Distribuci√≥n sesgada a la derecha")
    else:
        print("    ‚Üí Distribuci√≥n sesgada a la izquierda")
    
    print(f"  Curtosis: {kurt:.4f}")
    if abs(kurt) < 0.5:
        print("    ‚Üí Distribuci√≥n mesoc√∫rtica (normal)")
    elif kurt > 0:
        print("    ‚Üí Distribuci√≥n leptoc√∫rtica (colas pesadas)")
    else:
        print("    ‚Üí Distribuci√≥n platic√∫rtica (colas ligeras)")

    # 5. Test Chi-cuadrado de independencia
    print("\n" + "‚îÄ"*70)
    print("üìä TEST CHI-CUADRADO - Independencia de Variables")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Determinar si dos variables categ√≥ricas est√°n relacionadas")
    print("üîß Algoritmo: Compara frecuencias observadas vs esperadas")
    print("   ‚Ä¢ H0: Las variables son independientes (no relacionadas)")
    print("   ‚Ä¢ H1: Las variables son dependientes (relacionadas)")
    print("üìà Valores posibles:")
    print("   ‚Ä¢ œá¬≤ (Chi-cuadrado): ‚â• 0 (valores altos = m√°s dependencia)")
    print("   ‚Ä¢ P-valor: 0 a 1")
    print("   ‚Ä¢ Grados de libertad: (filas-1) √ó (columnas-1)")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ p < 0.05: Rechazamos H0 ‚Üí Variables DEPENDIENTES")
    print("   ‚Ä¢ p ‚â• 0.05: No rechazamos H0 ‚Üí Variables INDEPENDIENTES")
    print()

    print("--- Test Chi-cuadrado: Fuel_Type √ó Sales_Classification ---")
    contingency_table = pd.crosstab(df['Fuel_Type'], df['Sales_Classification'])
    chi2, p_value, dof, _ = stats.chi2_contingency(contingency_table)
    print(f"  Chi-cuadrado (œá¬≤): {chi2:.4f}")
    print(f"  P-valor: {p_value:.6f}")
    print(f"  Grados de libertad: {dof}")
    if p_value < 0.05:
        print("  ‚úÖ Las variables son dependientes (p < 0.05)")
    else:
        print("  ‚ùå Las variables son independientes (p ‚â• 0.05)")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    if p_value < 0.05:
        print("   ‚Ä¢ El tipo de combustible S√ç influye en la clasificaci√≥n de ventas")
        print("   ‚Ä¢ Hay una relaci√≥n estad√≠sticamente significativa")
        print("   ‚Ä¢ Recomendaci√≥n: Analizar qu√© combustibles tienen mejores ventas")
    else:
        print("   ‚Ä¢ El tipo de combustible NO influye en la clasificaci√≥n de ventas")
        print("   ‚Ä¢ Las variables son independientes")
        print("   ‚Ä¢ Las ventas altas/bajas ocurren por igual en todos los combustibles")
    
    # 6. Correlaci√≥n de Spearman (no param√©trica)
    print("\n--- Correlaci√≥n de Spearman: Precio vs Kilometraje ---")
    corr, p_value = stats.spearmanr(df['Price_USD'], df['Mileage_KM'])
    print(f"  Coeficiente de Spearman: {corr:.4f}")
    print(f"  P-valor: {p_value:.6f}")
    if abs(corr) > 0.7:
        print("  ‚Üí Correlaci√≥n fuerte")
    elif abs(corr) > 0.3:
        print("  ‚Üí Correlaci√≥n moderada")
    else:
        print("  ‚Üí Correlaci√≥n d√©bil")
    
    # 7. An√°lisis de percentiles avanzado
    print("\n--- An√°lisis de Percentiles Detallado ---")
    percentiles = [10, 25, 50, 75, 90, 95, 99]
    print("  Percentiles de Precio:")
    for p in percentiles:
        valor = np.percentile(precios, p)
        print(f"    P{p}: ${valor:,.2f}")


# =============================================================================
# NIVEL 3: CIENCIA DE DATOS CON SCIKIT-LEARN
# =============================================================================

def ciencia_datos_sklearn(df):
    """An√°lisis de ciencia de datos usando scikit-learn."""
    print("\n" + "="*70)
    print("NIVEL 3: CIENCIA DE DATOS - Scikit-Learn & Machine Learning")
    print("="*70)
    
    print("\nüìÅ Archivo: BMW sales data (2010-2024) (1).csv")
    print("üìã Descripci√≥n: An√°lisis avanzado de ciencia de datos usando scikit-learn")
    print("               para clustering, PCA, regresi√≥n y an√°lisis predictivo.")
    
    # Preparar datos
    df_ml = df.copy()
    
    # 1. Clustering con K-Means
    print("\n" + "‚îÄ"*70)
    print("ü§ñ CLUSTERING K-MEANS - Segmentaci√≥n Autom√°tica")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Agrupar veh√≠culos similares autom√°ticamente")
    print("üîß Algoritmo: K-Means (aprendizaje no supervisado)")
    print("   1. Selecciona K centroides aleatorios")
    print("   2. Asigna cada punto al centroide m√°s cercano")
    print("   3. Recalcula centroides como promedio del grupo")
    print("   4. Repite hasta convergencia")
    print("üìà Valores posibles:")
    print("   ‚Ä¢ Clusters: 0, 1, 2, ... (etiquetas de grupo)")
    print("   ‚Ä¢ Inercia: ‚â• 0 (suma de distancias al centroide, menor = mejor)")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ Cada cluster representa un segmento de mercado")
    print("   ‚Ä¢ Inercia baja = clusters bien definidos")
    print("   ‚Ä¢ Distribuci√≥n equilibrada = segmentos similares en tama√±o")
    print()

    print("--- Clustering K-Means: Segmentaci√≥n de Veh√≠culos ---")
    features_clustering = ['Price_USD', 'Mileage_KM', 'Engine_Size_L', 'Sales_Volume']
    X_cluster = df_ml[features_clustering].copy()

    # Normalizar datos
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_cluster)

    # Aplicar K-Means
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    df_ml['Cluster'] = kmeans.fit_predict(X_scaled)

    print(f"  N√∫mero de clusters: 3")
    print(f"  Inercia: {kmeans.inertia_:.2f}")
    print("\n  Distribuci√≥n de veh√≠culos por cluster:")
    cluster_counts = df_ml['Cluster'].value_counts().sort_index()
    for cluster, count in cluster_counts.items():
        print(f"    Cluster {cluster}: {count:,} veh√≠culos ({count/len(df_ml)*100:.1f}%)")

    print("\n  Caracter√≠sticas promedio por cluster:")
    cluster_stats = df_ml.groupby('Cluster')[features_clustering].mean()
    print(cluster_stats.round(2))

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    # Identificar caracter√≠sticas de cada cluster
    for cluster in range(3):
        stats = cluster_stats.loc[cluster]
        print(f"\n   Cluster {cluster}:")
        if stats['Price_USD'] < 60000:
            print(f"     ‚Ä¢ Segmento: ECON√ìMICO (${stats['Price_USD']:,.0f})")
        elif stats['Price_USD'] < 90000:
            print(f"     ‚Ä¢ Segmento: MEDIO (${stats['Price_USD']:,.0f})")
        else:
            print(f"     ‚Ä¢ Segmento: PREMIUM (${stats['Price_USD']:,.0f})")
        print(f"     ‚Ä¢ Kilometraje promedio: {stats['Mileage_KM']:,.0f} km")
        print(f"     ‚Ä¢ Volumen de ventas: {stats['Sales_Volume']:,.0f} unidades")

    # 2. PCA - An√°lisis de Componentes Principales
    print("\n" + "‚îÄ"*70)
    print("ü§ñ PCA - An√°lisis de Componentes Principales")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Reducir dimensiones manteniendo la informaci√≥n importante")
    print("üîß Algoritmo: Principal Component Analysis")
    print("   ‚Ä¢ Encuentra direcciones de m√°xima varianza en los datos")
    print("   ‚Ä¢ Transforma datos a nuevas coordenadas (componentes principales)")
    print("   ‚Ä¢ Reduce de N dimensiones a 2-3 para visualizaci√≥n")
    print("üìà Valores posibles:")
    print("   ‚Ä¢ Varianza explicada: 0% a 100% por componente")
    print("   ‚Ä¢ Suma de varianzas: Informaci√≥n total retenida")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ >70% varianza total: Buena reducci√≥n dimensional")
    print("   ‚Ä¢ <50% varianza total: Se pierde mucha informaci√≥n")
    print("   ‚Ä¢ PC1 > PC2: Primera componente es m√°s importante")
    print()

    print("--- PCA: Reducci√≥n de Dimensionalidad ---")
    pca = PCA(n_components=2)
    _ = pca.fit_transform(X_scaled)

    print(f"  Varianza explicada por componente:")
    for i, var in enumerate(pca.explained_variance_ratio_):
        print(f"    PC{i+1}: {var*100:.2f}%")
    varianza_total = sum(pca.explained_variance_ratio_)*100
    print(f"  Varianza total explicada: {varianza_total:.2f}%")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    if varianza_total > 70:
        print(f"   ‚Ä¢ Excelente: {varianza_total:.1f}% de informaci√≥n retenida")
        print("   ‚Ä¢ Las 2 componentes capturan bien la estructura de los datos")
    elif varianza_total > 50:
        print(f"   ‚Ä¢ Aceptable: {varianza_total:.1f}% de informaci√≥n retenida")
        print("   ‚Ä¢ Se pierde algo de informaci√≥n pero es √∫til para visualizaci√≥n")
    else:
        print(f"   ‚Ä¢ Limitado: Solo {varianza_total:.1f}% de informaci√≥n retenida")
        print("   ‚Ä¢ Los datos tienen estructura compleja, dif√≠cil de reducir")

    # 3. Regresi√≥n Lineal: Predecir precio
    print("\n" + "‚îÄ"*70)
    print("ü§ñ REGRESI√ìN LINEAL - Predicci√≥n de Precios")
    print("‚îÄ"*70)
    print("üéØ Objetivo: Predecir el precio bas√°ndose en caracter√≠sticas del veh√≠culo")
    print("üîß Algoritmo: Regresi√≥n Lineal (aprendizaje supervisado)")
    print("   ‚Ä¢ Encuentra la mejor l√≠nea/plano que ajusta los datos")
    print("   ‚Ä¢ Ecuaci√≥n: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô")
    print("   ‚Ä¢ Minimiza el error cuadr√°tico medio (MSE)")
    print("üìà M√©tricas de evaluaci√≥n:")
    print("   ‚Ä¢ R¬≤ Score: -‚àû a 1 (1 = predicci√≥n perfecta, 0 = modelo in√∫til)")
    print("   ‚Ä¢ RMSE: ‚â• 0 (error promedio en unidades originales)")
    print("   ‚Ä¢ MAE: ‚â• 0 (error absoluto promedio)")
    print("üí° Interpretaci√≥n:")
    print("   ‚Ä¢ R¬≤ > 0.7: Modelo excelente")
    print("   ‚Ä¢ 0.3 < R¬≤ < 0.7: Modelo aceptable")
    print("   ‚Ä¢ R¬≤ < 0.3: Modelo pobre")
    print("   ‚Ä¢ Coeficientes positivos: Aumentan el precio")
    print("   ‚Ä¢ Coeficientes negativos: Disminuyen el precio")
    print()

    print("--- Regresi√≥n Lineal: Predicci√≥n de Precios ---")

    # Codificar variables categ√≥ricas
    le_fuel = LabelEncoder()
    le_trans = LabelEncoder()
    le_region = LabelEncoder()

    df_ml['Fuel_Type_Encoded'] = le_fuel.fit_transform(df_ml['Fuel_Type'])
    df_ml['Transmission_Encoded'] = le_trans.fit_transform(df_ml['Transmission'])
    df_ml['Region_Encoded'] = le_region.fit_transform(df_ml['Region'])

    # Features para regresi√≥n
    features_reg = ['Mileage_KM', 'Engine_Size_L', 'Sales_Volume',
                    'Fuel_Type_Encoded', 'Transmission_Encoded', 'Region_Encoded']
    X = df_ml[features_reg]
    y = df_ml['Price_USD']

    # Dividir en train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Entrenar modelo
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Predicciones
    y_pred = model.predict(X_test)

    # M√©tricas
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = np.mean(np.abs(y_test - y_pred))

    print(f"  R¬≤ Score: {r2:.4f}")
    print(f"  RMSE: ${rmse:,.2f}")
    print(f"  MAE: ${mae:,.2f}")

    print("\n  Importancia de caracter√≠sticas (coeficientes):")
    for feature, coef in zip(features_reg, model.coef_):
        print(f"    {feature}: {coef:.2f}")

    print("\n‚úÖ Interpretaci√≥n de resultados:")
    if r2 > 0.7:
        print(f"   ‚Ä¢ R¬≤ = {r2:.4f}: EXCELENTE capacidad predictiva")
        print("   ‚Ä¢ El modelo explica >70% de la variabilidad en precios")
    elif r2 > 0.3:
        print(f"   ‚Ä¢ R¬≤ = {r2:.4f}: ACEPTABLE capacidad predictiva")
        print("   ‚Ä¢ El modelo captura algunas tendencias pero no todas")
    elif r2 > 0:
        print(f"   ‚Ä¢ R¬≤ = {r2:.4f}: POBRE capacidad predictiva")
        print("   ‚Ä¢ El modelo apenas mejora una predicci√≥n simple")
    else:
        print(f"   ‚Ä¢ R¬≤ = {r2:.4f}: MODELO IN√öTIL")
        print("   ‚Ä¢ El modelo es peor que simplemente usar el promedio")

    print(f"   ‚Ä¢ Error promedio: ${mae:,.2f} (MAE)")
    print(f"   ‚Ä¢ Error cuadr√°tico: ${rmse:,.2f} (RMSE)")

    # Identificar caracter√≠sticas m√°s importantes
    coef_abs = [(feat, abs(coef)) for feat, coef in zip(features_reg, model.coef_)]
    coef_abs.sort(key=lambda x: x[1], reverse=True)
    print(f"   ‚Ä¢ Caracter√≠stica m√°s influyente: {coef_abs[0][0]}")

    # 4. An√°lisis de outliers con IQR (m√©todo robusto)
    print("\n--- Detecci√≥n de Outliers (M√©todo IQR) ---")
    Q1 = df['Price_USD'].quantile(0.25)
    Q3 = df['Price_USD'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = df[(df['Price_USD'] < lower_bound) | (df['Price_USD'] > upper_bound)]
    print(f"  Outliers detectados: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)")
    print(f"  Rango normal: ${lower_bound:,.2f} - ${upper_bound:,.2f}")

    # 5. An√°lisis de tendencias temporales
    print("\n--- An√°lisis de Tendencias Temporales ---")
    ventas_anuales = df.groupby('Year').agg({
        'Sales_Volume': 'sum',
        'Price_USD': 'mean'
    }).reset_index()

    print("  Evoluci√≥n de ventas por a√±o:")
    for _, row in ventas_anuales.head(5).iterrows():
        print(f"    {int(row['Year'])}: {row['Sales_Volume']:,.0f} unidades, Precio prom: ${row['Price_USD']:,.2f}")
    print("    ...")
    for _, row in ventas_anuales.tail(3).iterrows():
        print(f"    {int(row['Year'])}: {row['Sales_Volume']:,.0f} unidades, Precio prom: ${row['Price_USD']:,.2f}")

    # 6. An√°lisis de segmentaci√≥n avanzada
    print("\n--- Segmentaci√≥n Avanzada por Valor de Cliente ---")
    df_ml['Customer_Value'] = df_ml['Price_USD'] * df_ml['Sales_Volume']

    # Crear segmentos usando cuartiles
    df_ml['Value_Segment'] = pd.qcut(df_ml['Customer_Value'],
                                      q=4,
                                      labels=['Bajo', 'Medio', 'Alto', 'Premium'])

    segment_stats = df_ml.groupby('Value_Segment').agg({
        'Customer_Value': ['count', 'mean', 'sum']
    })

    print("  Distribuci√≥n por segmento de valor:")
    for segment in ['Bajo', 'Medio', 'Alto', 'Premium']:
        count = segment_stats.loc[segment, ('Customer_Value', 'count')]
        mean_val = segment_stats.loc[segment, ('Customer_Value', 'mean')]
        total_val = segment_stats.loc[segment, ('Customer_Value', 'sum')]
        print(f"    {segment}: {count:,} veh√≠culos, Valor prom: ${mean_val:,.2f}, Total: ${total_val:,.2f}")


# =============================================================================
# VISUALIZACIONES AVANZADAS - NIVEL EXPERTO
# =============================================================================

def crear_visualizaciones(df):
    """
    Crea visualizaciones profesionales de nivel experto en ciencia de datos.

    Incluye:
    - An√°lisis de distribuciones multivariadas
    - Visualizaciones estad√≠sticas avanzadas
    - Dashboards interactivos
    - An√°lisis de segmentaci√≥n
    - Mapas de calor avanzados
    - An√°lisis temporal sofisticado
    - Visualizaciones de machine learning
    """
    print("\n" + "="*70)
    print("üé® VISUALIZACIONES PROFESIONALES - NIVEL EXPERTO")
    print("="*70)
    print("\nüéØ Objetivo: Crear visualizaciones de calidad publicable para an√°lisis")
    print("üìä Total de visualizaciones: 15 gr√°ficos profesionales")
    print("üíæ Formato: PNG de alta resoluci√≥n (300 DPI)")
    print("\nüìÅ Archivo: BMW sales data (2010-2024) (1).csv")
    print()

    # Configurar estilo profesional
    plt.style.use('seaborn-v0_8-darkgrid')
    sns.set_palette("husl")
    sns.set_context("notebook", font_scale=1.2)

    # Colores profesionales
    colors_primary = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#6A994E']
    colors_sequential = sns.color_palette("rocket", as_cmap=True)
    colors_diverging = sns.color_palette("vlag", as_cmap=True)

    # =========================================================================
    # 1. DASHBOARD MULTIVARIADO - An√°lisis Exploratorio Completo
    # =========================================================================
    print("\nüìä [1/15] Dashboard Exploratorio Multivariado")
    print("   ‚Üí An√°lisis: Distribuciones, outliers, y estad√≠sticas clave")

    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

    # Subplot 1: Distribuci√≥n de precios con estad√≠sticas
    ax1 = fig.add_subplot(gs[0, :2])
    sns.histplot(data=df, x='Price_USD', kde=True, bins=60, color='#2E86AB', alpha=0.7, ax=ax1)
    mean_price = df['Price_USD'].mean()
    median_price = df['Price_USD'].median()
    ax1.axvline(mean_price, color='red', linestyle='--', linewidth=2, label=f'Media: ${mean_price:,.0f}')
    ax1.axvline(median_price, color='green', linestyle='--', linewidth=2, label=f'Mediana: ${median_price:,.0f}')
    ax1.set_title('Distribuci√≥n de Precios con KDE', fontsize=14, fontweight='bold', pad=15)
    ax1.set_xlabel('Precio (USD)', fontsize=11)
    ax1.set_ylabel('Frecuencia', fontsize=11)
    ax1.legend(fontsize=10)
    ax1.grid(alpha=0.3)

    # Subplot 2: Estad√≠sticas clave
    ax2 = fig.add_subplot(gs[0, 2])
    ax2.axis('off')
    stats_text = f"""
    ESTAD√çSTICAS CLAVE
    {'‚îÄ'*25}

    Media:     ${mean_price:,.0f}
    Mediana:   ${median_price:,.0f}
    Desv. Std: ${df['Price_USD'].std():,.0f}

    M√≠nimo:    ${df['Price_USD'].min():,.0f}
    M√°ximo:    ${df['Price_USD'].max():,.0f}

    Q1 (25%):  ${df['Price_USD'].quantile(0.25):,.0f}
    Q3 (75%):  ${df['Price_USD'].quantile(0.75):,.0f}

    Registros: {len(df):,}
    """
    ax2.text(0.1, 0.5, stats_text, fontsize=10, family='monospace',
             verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

    # Subplot 3: Boxplot por tipo de combustible
    ax3 = fig.add_subplot(gs[1, :])
    sns.boxplot(data=df, x='Fuel_Type', y='Price_USD', palette='Set2', ax=ax3)
    ax3.set_title('Distribuci√≥n de Precios por Tipo de Combustible', fontsize=14, fontweight='bold', pad=15)
    ax3.set_xlabel('Tipo de Combustible', fontsize=11)
    ax3.set_ylabel('Precio (USD)', fontsize=11)
    ax3.grid(axis='y', alpha=0.3)

    # Subplot 4: Violin plot por transmisi√≥n
    ax4 = fig.add_subplot(gs[2, 0])
    sns.violinplot(data=df, x='Transmission', y='Price_USD', palette='muted', ax=ax4)
    ax4.set_title('Distribuci√≥n por Transmisi√≥n', fontsize=12, fontweight='bold')
    ax4.set_xlabel('Transmisi√≥n', fontsize=10)
    ax4.set_ylabel('Precio (USD)', fontsize=10)
    ax4.tick_params(labelsize=9)

    # Subplot 5: Scatter plot Precio vs Kilometraje
    ax5 = fig.add_subplot(gs[2, 1])
    sample_data = df.sample(min(3000, len(df)))
    scatter = ax5.scatter(sample_data['Mileage_KM'], sample_data['Price_USD'],
                         c=sample_data['Engine_Size_L'], cmap='viridis', alpha=0.5, s=20)
    ax5.set_title('Precio vs Kilometraje', fontsize=12, fontweight='bold')
    ax5.set_xlabel('Kilometraje (KM)', fontsize=10)
    ax5.set_ylabel('Precio (USD)', fontsize=10)
    plt.colorbar(scatter, ax=ax5, label='Tama√±o Motor (L)')
    ax5.tick_params(labelsize=9)

    # Subplot 6: Count plot de modelos top
    ax6 = fig.add_subplot(gs[2, 2])
    top_models = df['Model'].value_counts().head(8)
    top_models.plot(kind='barh', ax=ax6, color='#F18F01')
    ax6.set_title('Top 8 Modelos', fontsize=12, fontweight='bold')
    ax6.set_xlabel('Cantidad', fontsize=10)
    ax6.set_ylabel('Modelo', fontsize=10)
    ax6.tick_params(labelsize=9)

    fig.suptitle('DASHBOARD EXPLORATORIO - An√°lisis Multivariado BMW',
                 fontsize=18, fontweight='bold', y=0.995)
    plt.savefig('01_dashboard_exploratorio.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 2. MATRIZ DE CORRELACI√ìN AVANZADA
    # =========================================================================
    print("üìä [2/15] Matriz de Correlaci√≥n Avanzada con Clustering")
    print("   ‚Üí An√°lisis: Correlaciones jer√°rquicas y agrupamiento")

    # Preparar datos num√©ricos
    numeric_cols = ['Price_USD', 'Sales_Volume', 'Mileage_KM', 'Engine_Size_L', 'Year']
    corr_matrix = df[numeric_cols].corr()

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))

    # Heatmap con anotaciones
    sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,
                square=True, linewidths=1, cbar_kws={'label': 'Coeficiente de Correlaci√≥n'},
                ax=ax1, vmin=-1, vmax=1)
    ax1.set_title('Matriz de Correlaci√≥n de Pearson', fontsize=14, fontweight='bold', pad=15)

    # Clustermap (correlaci√≥n con clustering jer√°rquico)
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.3f', cmap='vlag', center=0,
                square=True, linewidths=1, cbar_kws={'label': 'Correlaci√≥n'},
                ax=ax2, vmin=-1, vmax=1)
    ax2.set_title('Matriz Triangular (sin duplicados)', fontsize=14, fontweight='bold', pad=15)

    fig.suptitle('AN√ÅLISIS DE CORRELACIONES - Variables Num√©ricas',
                 fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    plt.savefig('02_matriz_correlacion_avanzada.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 3. AN√ÅLISIS TEMPORAL AVANZADO
    # =========================================================================
    print("üìä [3/15] An√°lisis Temporal Multidimensional")
    print("   ‚Üí An√°lisis: Tendencias, estacionalidad, y evoluci√≥n de precios")

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Evoluci√≥n de ventas por a√±o
    ventas_anuales = df.groupby('Year')['Sales_Volume'].sum().reset_index()
    ax1 = axes[0, 0]
    ax1.plot(ventas_anuales['Year'], ventas_anuales['Sales_Volume'],
             marker='o', linewidth=3, markersize=10, color='#2E86AB')
    ax1.fill_between(ventas_anuales['Year'], ventas_anuales['Sales_Volume'], alpha=0.3, color='#2E86AB')
    ax1.set_title('Evoluci√≥n del Volumen de Ventas (2010-2024)', fontsize=13, fontweight='bold')
    ax1.set_xlabel('A√±o', fontsize=11)
    ax1.set_ylabel('Volumen de Ventas', fontsize=11)
    ax1.grid(True, alpha=0.3)
    ax1.ticklabel_format(style='plain', axis='y')

    # Evoluci√≥n de precios promedio por a√±o
    precios_anuales = df.groupby('Year')['Price_USD'].mean().reset_index()
    ax2 = axes[0, 1]
    ax2.plot(precios_anuales['Year'], precios_anuales['Price_USD'],
             marker='s', linewidth=3, markersize=10, color='#A23B72')
    ax2.fill_between(precios_anuales['Year'], precios_anuales['Price_USD'], alpha=0.3, color='#A23B72')
    ax2.set_title('Evoluci√≥n del Precio Promedio (2010-2024)', fontsize=13, fontweight='bold')
    ax2.set_xlabel('A√±o', fontsize=11)
    ax2.set_ylabel('Precio Promedio (USD)', fontsize=11)
    ax2.grid(True, alpha=0.3)

    # Heatmap: Ventas por A√±o y Tipo de Combustible
    ax3 = axes[1, 0]
    pivot_fuel = df.groupby(['Year', 'Fuel_Type'])['Sales_Volume'].sum().unstack(fill_value=0)
    sns.heatmap(pivot_fuel.T, annot=True, fmt='.0f', cmap='YlOrRd', ax=ax3, cbar_kws={'label': 'Ventas'})
    ax3.set_title('Ventas por A√±o y Tipo de Combustible', fontsize=13, fontweight='bold')
    ax3.set_xlabel('A√±o', fontsize=11)
    ax3.set_ylabel('Tipo de Combustible', fontsize=11)

    # Distribuci√≥n de ventas por regi√≥n a lo largo del tiempo
    ax4 = axes[1, 1]
    ventas_region_year = df.groupby(['Year', 'Region'])['Sales_Volume'].sum().unstack()
    ventas_region_year.plot(kind='area', stacked=True, ax=ax4, alpha=0.7, colormap='tab10')
    ax4.set_title('Evoluci√≥n de Ventas por Regi√≥n (Stacked)', fontsize=13, fontweight='bold')
    ax4.set_xlabel('A√±o', fontsize=11)
    ax4.set_ylabel('Volumen de Ventas', fontsize=11)
    ax4.legend(title='Regi√≥n', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    ax4.grid(True, alpha=0.3)

    fig.suptitle('AN√ÅLISIS TEMPORAL - Tendencias y Evoluci√≥n',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('03_analisis_temporal_avanzado.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 4. AN√ÅLISIS DE SEGMENTACI√ìN POR PRECIO
    # =========================================================================
    print("üìä [4/15] Segmentaci√≥n de Mercado por Precio")
    print("   ‚Üí An√°lisis: Segmentos de precio y caracter√≠sticas")

    # Crear segmentos de precio
    df_seg = df.copy()
    df_seg['Segmento_Precio'] = pd.cut(df_seg['Price_USD'],
                                        bins=[0, 50000, 75000, 100000, 150000],
                                        labels=['Econ√≥mico', 'Medio', 'Premium', 'Lujo'])

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Distribuci√≥n de segmentos
    ax1 = axes[0, 0]
    segment_counts = df_seg['Segmento_Precio'].value_counts()
    colors_seg = ['#6A994E', '#F18F01', '#A23B72', '#2E86AB']
    wedges, texts, autotexts = ax1.pie(segment_counts.values, labels=segment_counts.index,
                                        autopct='%1.1f%%', startangle=90, colors=colors_seg,
                                        textprops={'fontsize': 11, 'weight': 'bold'})
    ax1.set_title('Distribuci√≥n de Veh√≠culos por Segmento', fontsize=13, fontweight='bold')

    # Caracter√≠sticas por segmento
    ax2 = axes[0, 1]
    segment_stats = df_seg.groupby('Segmento_Precio').agg({
        'Price_USD': 'mean',
        'Sales_Volume': 'mean',
        'Mileage_KM': 'mean',
        'Engine_Size_L': 'mean'
    })
    segment_stats_norm = (segment_stats - segment_stats.min()) / (segment_stats.max() - segment_stats.min())
    segment_stats_norm.T.plot(kind='bar', ax=ax2, width=0.8, colormap='Set2')
    ax2.set_title('Caracter√≠sticas Normalizadas por Segmento', fontsize=13, fontweight='bold')
    ax2.set_xlabel('Caracter√≠stica', fontsize=11)
    ax2.set_ylabel('Valor Normalizado (0-1)', fontsize=11)
    ax2.legend(title='Segmento', fontsize=9)
    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')
    ax2.grid(axis='y', alpha=0.3)

    # Boxplot comparativo
    ax3 = axes[1, 0]
    sns.boxplot(data=df_seg, x='Segmento_Precio', y='Sales_Volume', palette='Set3', ax=ax3)
    ax3.set_title('Volumen de Ventas por Segmento', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Segmento de Precio', fontsize=11)
    ax3.set_ylabel('Volumen de Ventas', fontsize=11)
    ax3.grid(axis='y', alpha=0.3)

    # Heatmap: Segmento vs Tipo de Combustible
    ax4 = axes[1, 1]
    cross_tab = pd.crosstab(df_seg['Segmento_Precio'], df_seg['Fuel_Type'], normalize='index') * 100
    sns.heatmap(cross_tab, annot=True, fmt='.1f', cmap='Blues', ax=ax4, cbar_kws={'label': '% del Segmento'})
    ax4.set_title('Distribuci√≥n de Combustible por Segmento (%)', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Tipo de Combustible', fontsize=11)
    ax4.set_ylabel('Segmento de Precio', fontsize=11)

    fig.suptitle('SEGMENTACI√ìN DE MERCADO - An√°lisis por Precio',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('04_segmentacion_mercado.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 5. AN√ÅLISIS GEOGR√ÅFICO - VENTAS POR REGI√ìN
    # =========================================================================
    print("üìä [5/15] An√°lisis Geogr√°fico Detallado")
    print("   ‚Üí An√°lisis: Ventas, precios y preferencias por regi√≥n")

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Ventas totales por regi√≥n
    ax1 = axes[0, 0]
    ventas_region = df.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=True)
    ventas_region.plot(kind='barh', ax=ax1, color=colors_primary)
    ax1.set_title('Volumen Total de Ventas por Regi√≥n', fontsize=13, fontweight='bold')
    ax1.set_xlabel('Volumen de Ventas', fontsize=11)
    ax1.set_ylabel('Regi√≥n', fontsize=11)
    ax1.grid(axis='x', alpha=0.3)

    # Precio promedio por regi√≥n
    ax2 = axes[0, 1]
    precio_region = df.groupby('Region')['Price_USD'].mean().sort_values(ascending=False)
    bars = ax2.bar(range(len(precio_region)), precio_region.values, color=colors_primary)
    ax2.set_xticks(range(len(precio_region)))
    ax2.set_xticklabels(precio_region.index, rotation=45, ha='right')
    ax2.set_title('Precio Promedio por Regi√≥n', fontsize=13, fontweight='bold')
    ax2.set_xlabel('Regi√≥n', fontsize=11)
    ax2.set_ylabel('Precio Promedio (USD)', fontsize=11)
    ax2.grid(axis='y', alpha=0.3)

    # A√±adir valores en las barras
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'${height:,.0f}', ha='center', va='bottom', fontsize=9)

    # Preferencias de combustible por regi√≥n
    ax3 = axes[1, 0]
    fuel_region = pd.crosstab(df['Region'], df['Fuel_Type'], normalize='index') * 100
    fuel_region.plot(kind='bar', stacked=True, ax=ax3, colormap='Set2')
    ax3.set_title('Preferencias de Combustible por Regi√≥n (%)', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Regi√≥n', fontsize=11)
    ax3.set_ylabel('Porcentaje', fontsize=11)
    ax3.legend(title='Tipo de Combustible', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')
    ax3.grid(axis='y', alpha=0.3)

    # Scatter: Ventas vs Precio por regi√≥n
    ax4 = axes[1, 1]
    region_summary = df.groupby('Region').agg({
        'Sales_Volume': 'sum',
        'Price_USD': 'mean'
    }).reset_index()

    scatter = ax4.scatter(region_summary['Sales_Volume'], region_summary['Price_USD'],
                         s=500, alpha=0.6, c=range(len(region_summary)), cmap='viridis')

    for idx, row in region_summary.iterrows():
        ax4.annotate(row['Region'], (row['Sales_Volume'], row['Price_USD']),
                    fontsize=10, ha='center', va='center', weight='bold')

    ax4.set_title('Ventas vs Precio Promedio por Regi√≥n', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Volumen Total de Ventas', fontsize=11)
    ax4.set_ylabel('Precio Promedio (USD)', fontsize=11)
    ax4.grid(True, alpha=0.3)

    fig.suptitle('AN√ÅLISIS GEOGR√ÅFICO - Ventas y Preferencias por Regi√≥n',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('05_analisis_geografico.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print("\n‚úÖ Visualizaciones 1-5 completadas!")

    # =========================================================================
    # 6. AN√ÅLISIS DE MODELOS - TOP PERFORMERS
    # =========================================================================
    print("üìä [6/15] An√°lisis de Modelos Top Performers")
    print("   ‚Üí An√°lisis: Modelos m√°s vendidos y rentables")

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Top 10 modelos por volumen de ventas
    ax1 = axes[0, 0]
    top_models_sales = df.groupby('Model')['Sales_Volume'].sum().sort_values(ascending=False).head(10)
    top_models_sales.plot(kind='barh', ax=ax1, color='#2E86AB')
    ax1.set_title('Top 10 Modelos por Volumen de Ventas', fontsize=13, fontweight='bold')
    ax1.set_xlabel('Volumen Total de Ventas', fontsize=11)
    ax1.set_ylabel('Modelo', fontsize=11)
    ax1.grid(axis='x', alpha=0.3)

    # Top 10 modelos por precio promedio
    ax2 = axes[0, 1]
    top_models_price = df.groupby('Model')['Price_USD'].mean().sort_values(ascending=False).head(10)
    top_models_price.plot(kind='barh', ax=ax2, color='#A23B72')
    ax2.set_title('Top 10 Modelos por Precio Promedio', fontsize=13, fontweight='bold')
    ax2.set_xlabel('Precio Promedio (USD)', fontsize=11)
    ax2.set_ylabel('Modelo', fontsize=11)
    ax2.grid(axis='x', alpha=0.3)

    # Distribuci√≥n de modelos por tipo de combustible
    ax3 = axes[1, 0]
    model_fuel = pd.crosstab(df['Model'], df['Fuel_Type'])
    top_10_models = df['Model'].value_counts().head(10).index
    model_fuel_top = model_fuel.loc[top_10_models]
    model_fuel_top.plot(kind='bar', stacked=True, ax=ax3, colormap='Set3')
    ax3.set_title('Distribuci√≥n de Combustible - Top 10 Modelos', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Modelo', fontsize=11)
    ax3.set_ylabel('Cantidad', fontsize=11)
    ax3.legend(title='Combustible', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')
    ax3.grid(axis='y', alpha=0.3)

    # Scatter: Precio vs Ventas por modelo (top 15)
    ax4 = axes[1, 1]
    model_summary = df.groupby('Model').agg({
        'Sales_Volume': 'sum',
        'Price_USD': 'mean'
    }).reset_index()
    top_15_models = df['Model'].value_counts().head(15).index
    model_summary_top = model_summary[model_summary['Model'].isin(top_15_models)]

    scatter = ax4.scatter(model_summary_top['Sales_Volume'], model_summary_top['Price_USD'],
                         s=300, alpha=0.6, c=range(len(model_summary_top)), cmap='plasma')

    for _, row in model_summary_top.iterrows():
        ax4.annotate(row['Model'], (row['Sales_Volume'], row['Price_USD']),
                    fontsize=8, ha='center', va='bottom')

    ax4.set_title('Precio vs Ventas - Top 15 Modelos', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Volumen Total de Ventas', fontsize=11)
    ax4.set_ylabel('Precio Promedio (USD)', fontsize=11)
    ax4.grid(True, alpha=0.3)

    fig.suptitle('AN√ÅLISIS DE MODELOS - Top Performers',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('06_analisis_modelos.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 7. AN√ÅLISIS DE DISTRIBUCIONES ESTAD√çSTICAS
    # =========================================================================
    print("üìä [7/15] An√°lisis de Distribuciones Estad√≠sticas")
    print("   ‚Üí An√°lisis: QQ-plots, distribuciones y normalidad")

    from scipy import stats

    fig, axes = plt.subplots(2, 3, figsize=(20, 12))

    # Histograma con curva normal
    ax1 = axes[0, 0]
    mu, sigma = df['Price_USD'].mean(), df['Price_USD'].std()
    n, bins, patches = ax1.hist(df['Price_USD'], bins=50, density=True, alpha=0.7, color='#2E86AB')
    y = stats.norm.pdf(bins, mu, sigma)
    ax1.plot(bins, y, 'r--', linewidth=2, label='Distribuci√≥n Normal Te√≥rica')
    ax1.set_title('Distribuci√≥n de Precios vs Normal', fontsize=12, fontweight='bold')
    ax1.set_xlabel('Precio (USD)', fontsize=10)
    ax1.set_ylabel('Densidad', fontsize=10)
    ax1.legend()
    ax1.grid(alpha=0.3)

    # QQ-Plot para precios
    ax2 = axes[0, 1]
    stats.probplot(df['Price_USD'], dist="norm", plot=ax2)
    ax2.set_title('Q-Q Plot - Precios', fontsize=12, fontweight='bold')
    ax2.grid(alpha=0.3)

    # Boxplot comparativo m√∫ltiple
    ax3 = axes[0, 2]
    data_to_plot = [df[df['Fuel_Type'] == ft]['Price_USD'].values for ft in df['Fuel_Type'].unique()]
    bp = ax3.boxplot(data_to_plot, labels=df['Fuel_Type'].unique(), patch_artist=True)
    for patch, color in zip(bp['boxes'], colors_primary):
        patch.set_facecolor(color)
    ax3.set_title('Boxplot Comparativo por Combustible', fontsize=12, fontweight='bold')
    ax3.set_xlabel('Tipo de Combustible', fontsize=10)
    ax3.set_ylabel('Precio (USD)', fontsize=10)
    ax3.grid(axis='y', alpha=0.3)

    # Distribuci√≥n de kilometraje
    ax4 = axes[1, 0]
    sns.histplot(data=df, x='Mileage_KM', kde=True, bins=50, color='#F18F01', ax=ax4)
    ax4.set_title('Distribuci√≥n de Kilometraje', fontsize=12, fontweight='bold')
    ax4.set_xlabel('Kilometraje (KM)', fontsize=10)
    ax4.set_ylabel('Frecuencia', fontsize=10)
    ax4.grid(alpha=0.3)

    # Distribuci√≥n de tama√±o de motor
    ax5 = axes[1, 1]
    sns.histplot(data=df, x='Engine_Size_L', kde=True, bins=30, color='#6A994E', ax=ax5)
    ax5.set_title('Distribuci√≥n de Tama√±o de Motor', fontsize=12, fontweight='bold')
    ax5.set_xlabel('Tama√±o de Motor (L)', fontsize=10)
    ax5.set_ylabel('Frecuencia', fontsize=10)
    ax5.grid(alpha=0.3)

    # Distribuci√≥n de volumen de ventas
    ax6 = axes[1, 2]
    sns.histplot(data=df, x='Sales_Volume', kde=True, bins=50, color='#C73E1D', ax=ax6)
    ax6.set_title('Distribuci√≥n de Volumen de Ventas', fontsize=12, fontweight='bold')
    ax6.set_xlabel('Volumen de Ventas', fontsize=10)
    ax6.set_ylabel('Frecuencia', fontsize=10)
    ax6.grid(alpha=0.3)

    fig.suptitle('AN√ÅLISIS DE DISTRIBUCIONES ESTAD√çSTICAS',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('07_distribuciones_estadisticas.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print("\n‚úÖ Visualizaciones 6-7 completadas!")

    # =========================================================================
    # 8. PAIRPLOT - RELACIONES MULTIVARIADAS
    # =========================================================================
    print("üìä [8/15] Pairplot - An√°lisis de Relaciones Multivariadas")
    print("   ‚Üí An√°lisis: Relaciones entre todas las variables num√©ricas")

    # Seleccionar muestra para pairplot (m√°s r√°pido)
    sample_size = min(2000, len(df))
    df_sample = df.sample(sample_size, random_state=42)

    # Crear pairplot
    pairplot_vars = ['Price_USD', 'Mileage_KM', 'Engine_Size_L', 'Sales_Volume']
    g = sns.pairplot(df_sample[pairplot_vars + ['Fuel_Type']], hue='Fuel_Type',
                     palette='Set2', diag_kind='kde', plot_kws={'alpha': 0.6, 's': 30},
                     height=3)
    g.fig.suptitle('PAIRPLOT - Relaciones Multivariadas (Muestra de 2,000 registros)',
                   fontsize=16, fontweight='bold', y=1.01)
    plt.savefig('08_pairplot_multivariado.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 9. AN√ÅLISIS DE CLUSTERING (K-MEANS VISUALIZATION)
    # =========================================================================
    print("üìä [9/15] Visualizaci√≥n de Clustering K-Means")
    print("   ‚Üí An√°lisis: Segmentaci√≥n autom√°tica de veh√≠culos")

    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA

    # Preparar datos para clustering
    features_clustering = ['Price_USD', 'Mileage_KM', 'Engine_Size_L', 'Sales_Volume']
    X_cluster = df[features_clustering].copy()

    # Normalizar
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_cluster)

    # K-Means
    kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)

    # PCA para visualizaci√≥n
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Scatter plot de clusters en espacio PCA
    ax1 = axes[0, 0]
    scatter = ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis',
                         alpha=0.6, s=20)
    ax1.scatter(pca.transform(kmeans.cluster_centers_)[:, 0],
               pca.transform(kmeans.cluster_centers_)[:, 1],
               c='red', marker='X', s=300, edgecolors='black', linewidths=2,
               label='Centroides')
    ax1.set_title('Clusters en Espacio PCA', fontsize=13, fontweight='bold')
    ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% varianza)', fontsize=11)
    ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% varianza)', fontsize=11)
    ax1.legend()
    ax1.grid(alpha=0.3)
    plt.colorbar(scatter, ax=ax1, label='Cluster')

    # Distribuci√≥n de clusters
    ax2 = axes[0, 1]
    cluster_counts = pd.Series(clusters).value_counts().sort_index()
    bars = ax2.bar(cluster_counts.index, cluster_counts.values, color=colors_primary)
    ax2.set_title('Distribuci√≥n de Veh√≠culos por Cluster', fontsize=13, fontweight='bold')
    ax2.set_xlabel('Cluster', fontsize=11)
    ax2.set_ylabel('Cantidad de Veh√≠culos', fontsize=11)
    ax2.grid(axis='y', alpha=0.3)

    # A√±adir porcentajes
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:,.0f}\n({height/len(clusters)*100:.1f}%)',
                ha='center', va='bottom', fontsize=10)

    # Caracter√≠sticas promedio por cluster
    ax3 = axes[1, 0]
    df_clustered = df.copy()
    df_clustered['Cluster'] = clusters
    cluster_means = df_clustered.groupby('Cluster')[features_clustering].mean()
    cluster_means_norm = (cluster_means - cluster_means.min()) / (cluster_means.max() - cluster_means.min())
    cluster_means_norm.T.plot(kind='bar', ax=ax3, width=0.8, colormap='viridis')
    ax3.set_title('Caracter√≠sticas Normalizadas por Cluster', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Caracter√≠stica', fontsize=11)
    ax3.set_ylabel('Valor Normalizado (0-1)', fontsize=11)
    ax3.legend(title='Cluster', fontsize=9)
    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=45, ha='right')
    ax3.grid(axis='y', alpha=0.3)

    # Heatmap de caracter√≠sticas por cluster
    ax4 = axes[1, 1]
    sns.heatmap(cluster_means.T, annot=True, fmt='.0f', cmap='YlOrRd', ax=ax4,
                cbar_kws={'label': 'Valor Promedio'})
    ax4.set_title('Heatmap de Caracter√≠sticas por Cluster', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Cluster', fontsize=11)
    ax4.set_ylabel('Caracter√≠stica', fontsize=11)

    fig.suptitle('AN√ÅLISIS DE CLUSTERING - K-Means con 4 Clusters',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('09_clustering_kmeans.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print("\n‚úÖ Visualizaciones 8-9 completadas!")

    # =========================================================================
    # 10. AN√ÅLISIS DE REGRESI√ìN LINEAL
    # =========================================================================
    print("üìä [10/15] An√°lisis de Regresi√≥n Lineal")
    print("   ‚Üí An√°lisis: Predicci√≥n de precios y residuos")

    from sklearn.linear_model import LinearRegression
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import r2_score, mean_squared_error

    # Preparar datos
    X_reg = df[['Mileage_KM', 'Engine_Size_L', 'Sales_Volume']].copy()
    y_reg = df['Price_USD'].copy()

    X_train, X_test, y_train, y_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

    # Entrenar modelo
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    # Calcular m√©tricas
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    residuals = y_test - y_pred

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Predicho vs Real
    ax1 = axes[0, 0]
    ax1.scatter(y_test, y_pred, alpha=0.5, s=20, color='#2E86AB')
    ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
             'r--', lw=2, label='Predicci√≥n Perfecta')
    ax1.set_title(f'Predicho vs Real (R¬≤ = {r2:.4f})', fontsize=13, fontweight='bold')
    ax1.set_xlabel('Precio Real (USD)', fontsize=11)
    ax1.set_ylabel('Precio Predicho (USD)', fontsize=11)
    ax1.legend()
    ax1.grid(alpha=0.3)

    # Distribuci√≥n de residuos
    ax2 = axes[0, 1]
    ax2.hist(residuals, bins=50, color='#A23B72', alpha=0.7, edgecolor='black')
    ax2.axvline(0, color='red', linestyle='--', linewidth=2, label='Residuo = 0')
    ax2.set_title('Distribuci√≥n de Residuos', fontsize=13, fontweight='bold')
    ax2.set_xlabel('Residuo (USD)', fontsize=11)
    ax2.set_ylabel('Frecuencia', fontsize=11)
    ax2.legend()
    ax2.grid(alpha=0.3)

    # Residuos vs Predicho
    ax3 = axes[1, 0]
    ax3.scatter(y_pred, residuals, alpha=0.5, s=20, color='#F18F01')
    ax3.axhline(0, color='red', linestyle='--', linewidth=2)
    ax3.set_title('Residuos vs Valores Predichos', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Precio Predicho (USD)', fontsize=11)
    ax3.set_ylabel('Residuo (USD)', fontsize=11)
    ax3.grid(alpha=0.3)

    # Importancia de caracter√≠sticas
    ax4 = axes[1, 1]
    feature_importance = pd.DataFrame({
        'Feature': X_reg.columns,
        'Coefficient': model.coef_
    }).sort_values('Coefficient', key=abs, ascending=True)

    colors_feat = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]
    ax4.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors_feat)
    ax4.set_title('Coeficientes del Modelo de Regresi√≥n', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Coeficiente', fontsize=11)
    ax4.set_ylabel('Caracter√≠stica', fontsize=11)
    ax4.axvline(0, color='black', linestyle='-', linewidth=1)
    ax4.grid(axis='x', alpha=0.3)

    # A√±adir m√©tricas
    metrics_text = f'RMSE: ${rmse:,.2f}\nR¬≤: {r2:.4f}'
    ax4.text(0.95, 0.95, metrics_text, transform=ax4.transAxes,
            fontsize=11, verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    fig.suptitle('AN√ÅLISIS DE REGRESI√ìN LINEAL - Predicci√≥n de Precios',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('10_regresion_lineal.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 11. DASHBOARD EJECUTIVO - KPIs
    # =========================================================================
    print("üìä [11/15] Dashboard Ejecutivo con KPIs")
    print("   ‚Üí An√°lisis: M√©tricas clave del negocio")

    fig = plt.figure(figsize=(20, 12))
    gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.4)

    # KPI 1: Ventas Totales
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.axis('off')
    total_sales = df['Sales_Volume'].sum()
    kpi_text = f"{total_sales:,.0f}"
    ax1.text(0.5, 0.6, kpi_text, fontsize=36, fontweight='bold',
            ha='center', va='center', color='#2E86AB')
    ax1.text(0.5, 0.3, 'VENTAS TOTALES', fontsize=14, ha='center', va='center')
    ax1.add_patch(plt.Rectangle((0.1, 0.1), 0.8, 0.8, fill=False, edgecolor='#2E86AB', linewidth=3))

    # KPI 2: Precio Promedio
    ax2 = fig.add_subplot(gs[0, 1])
    ax2.axis('off')
    avg_price = df['Price_USD'].mean()
    kpi_text = f"${avg_price:,.0f}"
    ax2.text(0.5, 0.6, kpi_text, fontsize=36, fontweight='bold',
            ha='center', va='center', color='#A23B72')
    ax2.text(0.5, 0.3, 'PRECIO PROMEDIO', fontsize=14, ha='center', va='center')
    ax2.add_patch(plt.Rectangle((0.1, 0.1), 0.8, 0.8, fill=False, edgecolor='#A23B72', linewidth=3))

    # KPI 3: Total de Modelos
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.axis('off')
    total_models = df['Model'].nunique()
    kpi_text = f"{total_models}"
    ax3.text(0.5, 0.6, kpi_text, fontsize=36, fontweight='bold',
            ha='center', va='center', color='#F18F01')
    ax3.text(0.5, 0.3, 'MODELOS √öNICOS', fontsize=14, ha='center', va='center')
    ax3.add_patch(plt.Rectangle((0.1, 0.1), 0.8, 0.8, fill=False, edgecolor='#F18F01', linewidth=3))

    # KPI 4: Total de Regiones
    ax4 = fig.add_subplot(gs[0, 3])
    ax4.axis('off')
    total_regions = df['Region'].nunique()
    kpi_text = f"{total_regions}"
    ax4.text(0.5, 0.6, kpi_text, fontsize=36, fontweight='bold',
            ha='center', va='center', color='#6A994E')
    ax4.text(0.5, 0.3, 'REGIONES', fontsize=14, ha='center', va='center')
    ax4.add_patch(plt.Rectangle((0.1, 0.1), 0.8, 0.8, fill=False, edgecolor='#6A994E', linewidth=3))

    # Gr√°fico 1: Tendencia de ventas
    ax5 = fig.add_subplot(gs[1, :2])
    ventas_year = df.groupby('Year')['Sales_Volume'].sum()
    ax5.plot(ventas_year.index, ventas_year.values, marker='o', linewidth=3,
            markersize=8, color='#2E86AB')
    ax5.fill_between(ventas_year.index, ventas_year.values, alpha=0.3, color='#2E86AB')
    ax5.set_title('Tendencia de Ventas Anuales', fontsize=13, fontweight='bold')
    ax5.set_xlabel('A√±o', fontsize=11)
    ax5.set_ylabel('Ventas', fontsize=11)
    ax5.grid(alpha=0.3)

    # Gr√°fico 2: Top 5 regiones
    ax6 = fig.add_subplot(gs[1, 2:])
    top_regions = df.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=False).head(5)
    top_regions.plot(kind='barh', ax=ax6, color=colors_primary)
    ax6.set_title('Top 5 Regiones por Ventas', fontsize=13, fontweight='bold')
    ax6.set_xlabel('Ventas Totales', fontsize=11)
    ax6.grid(axis='x', alpha=0.3)

    # Gr√°fico 3: Distribuci√≥n por combustible
    ax7 = fig.add_subplot(gs[2, :2])
    fuel_dist = df['Fuel_Type'].value_counts()
    ax7.pie(fuel_dist.values, labels=fuel_dist.index, autopct='%1.1f%%',
           colors=colors_primary, startangle=90)
    ax7.set_title('Distribuci√≥n por Tipo de Combustible', fontsize=13, fontweight='bold')

    # Gr√°fico 4: Distribuci√≥n por transmisi√≥n
    ax8 = fig.add_subplot(gs[2, 2:])
    trans_dist = df['Transmission'].value_counts()
    ax8.pie(trans_dist.values, labels=trans_dist.index, autopct='%1.1f%%',
           colors=['#2E86AB', '#A23B72'], startangle=90)
    ax8.set_title('Distribuci√≥n por Tipo de Transmisi√≥n', fontsize=13, fontweight='bold')

    fig.suptitle('DASHBOARD EJECUTIVO - KPIs y M√©tricas Clave',
                 fontsize=18, fontweight='bold', y=0.98)
    plt.savefig('11_dashboard_ejecutivo.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print("\n‚úÖ Visualizaciones 10-11 completadas!")

    # =========================================================================
    # 12. AN√ÅLISIS DE OUTLIERS Y ANOMAL√çAS
    # =========================================================================
    print("üìä [12/15] An√°lisis de Outliers y Anomal√≠as")
    print("   ‚Üí An√°lisis: Detecci√≥n de valores at√≠picos")

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Boxplot con outliers marcados - Precio
    ax1 = axes[0, 0]
    bp1 = ax1.boxplot([df['Price_USD']], vert=True, patch_artist=True,
                      widths=0.5, showfliers=True)
    bp1['boxes'][0].set_facecolor('#2E86AB')
    bp1['boxes'][0].set_alpha(0.7)
    ax1.set_title('Detecci√≥n de Outliers - Precio', fontsize=13, fontweight='bold')
    ax1.set_ylabel('Precio (USD)', fontsize=11)
    ax1.set_xticklabels(['Precio'])
    ax1.grid(axis='y', alpha=0.3)

    # A√±adir estad√≠sticas
    Q1 = df['Price_USD'].quantile(0.25)
    Q3 = df['Price_USD'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers_count = len(df[(df['Price_USD'] < lower_bound) | (df['Price_USD'] > upper_bound)])

    stats_text = f'Q1: ${Q1:,.0f}\nQ3: ${Q3:,.0f}\nIQR: ${IQR:,.0f}\nOutliers: {outliers_count}'
    ax1.text(0.98, 0.98, stats_text, transform=ax1.transAxes,
            fontsize=10, verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))

    # Boxplot con outliers - Kilometraje
    ax2 = axes[0, 1]
    bp2 = ax2.boxplot([df['Mileage_KM']], vert=True, patch_artist=True,
                      widths=0.5, showfliers=True)
    bp2['boxes'][0].set_facecolor('#A23B72')
    bp2['boxes'][0].set_alpha(0.7)
    ax2.set_title('Detecci√≥n de Outliers - Kilometraje', fontsize=13, fontweight='bold')
    ax2.set_ylabel('Kilometraje (KM)', fontsize=11)
    ax2.set_xticklabels(['Kilometraje'])
    ax2.grid(axis='y', alpha=0.3)

    # Z-Score para detecci√≥n de outliers
    ax3 = axes[1, 0]
    from scipy import stats as sp_stats
    z_scores = np.abs(sp_stats.zscore(df['Price_USD']))
    ax3.hist(z_scores, bins=50, color='#F18F01', alpha=0.7, edgecolor='black')
    ax3.axvline(3, color='red', linestyle='--', linewidth=2, label='Umbral Z=3')
    ax3.set_title('Distribuci√≥n de Z-Scores - Precio', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Z-Score', fontsize=11)
    ax3.set_ylabel('Frecuencia', fontsize=11)
    ax3.legend()
    ax3.grid(alpha=0.3)

    # Scatter plot con outliers marcados
    ax4 = axes[1, 1]
    outlier_mask = (df['Price_USD'] < lower_bound) | (df['Price_USD'] > upper_bound)
    ax4.scatter(df[~outlier_mask]['Mileage_KM'], df[~outlier_mask]['Price_USD'],
               alpha=0.5, s=20, color='#2E86AB', label='Normal')
    ax4.scatter(df[outlier_mask]['Mileage_KM'], df[outlier_mask]['Price_USD'],
               alpha=0.8, s=50, color='red', marker='x', label='Outliers')
    ax4.set_title('Outliers en Precio vs Kilometraje', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Kilometraje (KM)', fontsize=11)
    ax4.set_ylabel('Precio (USD)', fontsize=11)
    ax4.legend()
    ax4.grid(alpha=0.3)

    fig.suptitle('AN√ÅLISIS DE OUTLIERS Y ANOMAL√çAS',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('12_analisis_outliers.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 13. AN√ÅLISIS DE COMPOSICI√ìN Y PROPORCIONES
    # =========================================================================
    print("üìä [13/15] An√°lisis de Composici√≥n y Proporciones")
    print("   ‚Üí An√°lisis: Distribuciones y proporciones del mercado")

    fig, axes = plt.subplots(2, 3, figsize=(20, 12))

    # Treemap simulado con barras apiladas - Modelos por regi√≥n
    ax1 = axes[0, 0]
    top_5_models = df['Model'].value_counts().head(5).index
    model_region = df[df['Model'].isin(top_5_models)].groupby(['Model', 'Region']).size().unstack(fill_value=0)
    model_region.plot(kind='bar', stacked=True, ax=ax1, colormap='tab10')
    ax1.set_title('Top 5 Modelos por Regi√≥n', fontsize=13, fontweight='bold')
    ax1.set_xlabel('Modelo', fontsize=11)
    ax1.set_ylabel('Cantidad', fontsize=11)
    ax1.legend(title='Regi√≥n', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')
    ax1.grid(axis='y', alpha=0.3)

    # Donut chart - Clasificaci√≥n de ventas
    ax2 = axes[0, 1]
    sales_class = df['Sales_Classification'].value_counts()
    wedges, texts, autotexts = ax2.pie(sales_class.values, labels=sales_class.index,
                                        autopct='%1.1f%%', startangle=90,
                                        colors=colors_primary, pctdistance=0.85)
    centre_circle = plt.Circle((0, 0), 0.70, fc='white')
    ax2.add_artist(centre_circle)
    ax2.set_title('Clasificaci√≥n de Ventas', fontsize=13, fontweight='bold')

    # Stacked area - Evoluci√≥n de combustibles
    ax3 = axes[0, 2]
    fuel_year = df.groupby(['Year', 'Fuel_Type']).size().unstack(fill_value=0)
    fuel_year.plot(kind='area', stacked=True, ax=ax3, alpha=0.7, colormap='Set2')
    ax3.set_title('Evoluci√≥n de Tipos de Combustible', fontsize=13, fontweight='bold')
    ax3.set_xlabel('A√±o', fontsize=11)
    ax3.set_ylabel('Cantidad', fontsize=11)
    ax3.legend(title='Combustible', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax3.grid(alpha=0.3)

    # Waffle chart simulado - Distribuci√≥n de colores
    ax4 = axes[1, 0]
    color_dist = df['Color'].value_counts().head(8)
    color_dist.plot(kind='barh', ax=ax4, color=colors_primary)
    ax4.set_title('Top 8 Colores M√°s Populares', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Cantidad', fontsize=11)
    ax4.set_ylabel('Color', fontsize=11)
    ax4.grid(axis='x', alpha=0.3)

    # Sunburst simulado - Jerarqu√≠a de ventas
    ax5 = axes[1, 1]
    region_fuel = df.groupby(['Region', 'Fuel_Type']).size().unstack(fill_value=0)
    region_fuel_pct = region_fuel.div(region_fuel.sum(axis=1), axis=0) * 100
    region_fuel_pct.plot(kind='bar', stacked=True, ax=ax5, colormap='Spectral')
    ax5.set_title('Distribuci√≥n de Combustible por Regi√≥n (%)', fontsize=13, fontweight='bold')
    ax5.set_xlabel('Regi√≥n', fontsize=11)
    ax5.set_ylabel('Porcentaje', fontsize=11)
    ax5.legend(title='Combustible', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
    ax5.set_xticklabels(ax5.get_xticklabels(), rotation=45, ha='right')
    ax5.grid(axis='y', alpha=0.3)

    # Proporci√≥n de transmisiones por a√±o
    ax6 = axes[1, 2]
    trans_year = pd.crosstab(df['Year'], df['Transmission'], normalize='index') * 100
    trans_year.plot(kind='area', stacked=True, ax=ax6, alpha=0.7, color=['#2E86AB', '#A23B72'])
    ax6.set_title('Evoluci√≥n de Transmisiones (%)', fontsize=13, fontweight='bold')
    ax6.set_xlabel('A√±o', fontsize=11)
    ax6.set_ylabel('Porcentaje', fontsize=11)
    ax6.legend(title='Transmisi√≥n', fontsize=9)
    ax6.grid(alpha=0.3)

    fig.suptitle('AN√ÅLISIS DE COMPOSICI√ìN Y PROPORCIONES',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('13_composicion_proporciones.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print("\n‚úÖ Visualizaciones 12-13 completadas!")

    # =========================================================================
    # 14. AN√ÅLISIS COMPARATIVO MULTIDIMENSIONAL
    # =========================================================================
    print("üìä [14/15] An√°lisis Comparativo Multidimensional")
    print("   ‚Üí An√°lisis: Comparaciones complejas entre m√∫ltiples variables")

    fig, axes = plt.subplots(2, 2, figsize=(18, 12))

    # Radar chart - Comparaci√≥n de caracter√≠sticas por tipo de combustible
    ax1 = axes[0, 0]
    fuel_stats = df.groupby('Fuel_Type').agg({
        'Price_USD': 'mean',
        'Sales_Volume': 'mean',
        'Mileage_KM': 'mean',
        'Engine_Size_L': 'mean'
    })

    # Normalizar para radar chart
    fuel_stats_norm = (fuel_stats - fuel_stats.min()) / (fuel_stats.max() - fuel_stats.min())

    categories = list(fuel_stats_norm.columns)
    N = len(categories)
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    angles += angles[:1]

    ax1 = plt.subplot(2, 2, 1, projection='polar')
    for idx, fuel_type in enumerate(fuel_stats_norm.index):
        values = fuel_stats_norm.loc[fuel_type].values.tolist()
        values += values[:1]
        ax1.plot(angles, values, 'o-', linewidth=2, label=fuel_type, color=colors_primary[idx])
        ax1.fill(angles, values, alpha=0.15, color=colors_primary[idx])

    ax1.set_xticks(angles[:-1])
    ax1.set_xticklabels(categories, size=9)
    ax1.set_ylim(0, 1)
    ax1.set_title('Radar Chart - Caracter√≠sticas por Combustible', fontsize=13,
                 fontweight='bold', pad=20)
    ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=9)
    ax1.grid(True)

    # Heatmap de correlaci√≥n por segmento
    ax2 = axes[0, 1]
    df_temp = df.copy()
    df_temp['Price_Segment'] = pd.qcut(df_temp['Price_USD'], q=3, labels=['Bajo', 'Medio', 'Alto'])

    segment_corr = df_temp.groupby('Price_Segment')[['Price_USD', 'Sales_Volume', 'Mileage_KM']].corr()
    segment_corr_price = segment_corr.xs('Price_USD', level=1)

    sns.heatmap(segment_corr_price, annot=True, fmt='.3f', cmap='coolwarm', center=0,
                ax=ax2, cbar_kws={'label': 'Correlaci√≥n'}, vmin=-1, vmax=1)
    ax2.set_title('Correlaciones por Segmento de Precio', fontsize=13, fontweight='bold')
    ax2.set_xlabel('Variable', fontsize=11)
    ax2.set_ylabel('Segmento', fontsize=11)

    # Violin plot comparativo
    ax3 = axes[1, 0]
    df_sample_violin = df.sample(min(5000, len(df)))
    sns.violinplot(data=df_sample_violin, x='Fuel_Type', y='Price_USD',
                  hue='Transmission', split=True, palette='muted', ax=ax3)
    ax3.set_title('Distribuci√≥n de Precios: Combustible √ó Transmisi√≥n', fontsize=13, fontweight='bold')
    ax3.set_xlabel('Tipo de Combustible', fontsize=11)
    ax3.set_ylabel('Precio (USD)', fontsize=11)
    ax3.legend(title='Transmisi√≥n', fontsize=9)
    ax3.grid(axis='y', alpha=0.3)

    # Bubble chart - 3 dimensiones
    ax4 = axes[1, 1]
    model_summary = df.groupby('Model').agg({
        'Price_USD': 'mean',
        'Sales_Volume': 'sum',
        'Mileage_KM': 'mean'
    }).reset_index()

    top_15 = df['Model'].value_counts().head(15).index
    model_summary_top = model_summary[model_summary['Model'].isin(top_15)]

    scatter = ax4.scatter(model_summary_top['Price_USD'],
                         model_summary_top['Sales_Volume'],
                         s=model_summary_top['Mileage_KM']/500,  # Tama√±o por kilometraje
                         c=range(len(model_summary_top)),
                         cmap='viridis', alpha=0.6, edgecolors='black', linewidth=1)

    ax4.set_title('Bubble Chart: Precio √ó Ventas √ó Kilometraje', fontsize=13, fontweight='bold')
    ax4.set_xlabel('Precio Promedio (USD)', fontsize=11)
    ax4.set_ylabel('Ventas Totales', fontsize=11)
    ax4.grid(alpha=0.3)

    # A√±adir leyenda de tama√±o
    handles, labels = scatter.legend_elements(prop="sizes", alpha=0.6, num=4)
    legend = ax4.legend(handles, ['Bajo KM', 'Medio-Bajo', 'Medio-Alto', 'Alto KM'],
                       loc="upper right", title="Kilometraje", fontsize=8)

    fig.suptitle('AN√ÅLISIS COMPARATIVO MULTIDIMENSIONAL',
                 fontsize=16, fontweight='bold', y=0.995)
    plt.tight_layout()
    plt.savefig('14_analisis_comparativo.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    # =========================================================================
    # 15. RESUMEN ESTAD√çSTICO VISUAL COMPLETO
    # =========================================================================
    print("üìä [15/15] Resumen Estad√≠stico Visual Completo")
    print("   ‚Üí An√°lisis: S√≠ntesis visual de todos los an√°lisis")

    fig = plt.figure(figsize=(22, 14))
    gs = fig.add_gridspec(4, 4, hspace=0.4, wspace=0.4)

    # Panel 1: Distribuci√≥n de precios con estad√≠sticas
    ax1 = fig.add_subplot(gs[0:2, 0:2])
    n, bins, patches = ax1.hist(df['Price_USD'], bins=60, color='#2E86AB', alpha=0.7, edgecolor='black')

    # A√±adir l√≠neas de percentiles
    percentiles = [25, 50, 75]
    colors_perc = ['green', 'orange', 'red']
    for p, c in zip(percentiles, colors_perc):
        val = df['Price_USD'].quantile(p/100)
        ax1.axvline(val, color=c, linestyle='--', linewidth=2, label=f'P{p}: ${val:,.0f}')

    ax1.set_title('DISTRIBUCI√ìN DE PRECIOS CON PERCENTILES', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Precio (USD)', fontsize=11)
    ax1.set_ylabel('Frecuencia', fontsize=11)
    ax1.legend(fontsize=9)
    ax1.grid(alpha=0.3)

    # Panel 2: Top 10 modelos
    ax2 = fig.add_subplot(gs[0:2, 2:4])
    top_10_models = df['Model'].value_counts().head(10)
    bars = ax2.barh(range(len(top_10_models)), top_10_models.values, color=colors_primary)
    ax2.set_yticks(range(len(top_10_models)))
    ax2.set_yticklabels(top_10_models.index)
    ax2.set_title('TOP 10 MODELOS M√ÅS VENDIDOS', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Cantidad de Ventas', fontsize=11)
    ax2.grid(axis='x', alpha=0.3)

    # A√±adir valores
    for i, (bar, val) in enumerate(zip(bars, top_10_models.values)):
        ax2.text(val, i, f' {val:,}', va='center', fontsize=9)

    # Panel 3: Matriz de correlaci√≥n compacta
    ax3 = fig.add_subplot(gs[2, 0:2])
    corr_vars = ['Price_USD', 'Sales_Volume', 'Mileage_KM', 'Engine_Size_L']
    corr_matrix = df[corr_vars].corr()
    sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn', center=0,
                square=True, linewidths=2, cbar_kws={'label': 'Correlaci√≥n'},
                ax=ax3, vmin=-1, vmax=1)
    ax3.set_title('MATRIZ DE CORRELACI√ìN', fontsize=14, fontweight='bold')

    # Panel 4: Distribuci√≥n por regi√≥n
    ax4 = fig.add_subplot(gs[2, 2:4])
    region_sales = df.groupby('Region')['Sales_Volume'].sum().sort_values(ascending=True)
    region_sales.plot(kind='barh', ax=ax4, color=colors_primary)
    ax4.set_title('VENTAS POR REGI√ìN', fontsize=14, fontweight='bold')
    ax4.set_xlabel('Volumen de Ventas', fontsize=11)
    ax4.grid(axis='x', alpha=0.3)

    # Panel 5: Estad√≠sticas clave en tabla
    ax5 = fig.add_subplot(gs[3, :2])
    ax5.axis('off')

    stats_data = [
        ['M√©trica', 'Valor'],
        ['‚îÄ'*30, '‚îÄ'*30],
        ['Total de Registros', f'{len(df):,}'],
        ['Precio Promedio', f'${df["Price_USD"].mean():,.2f}'],
        ['Precio Mediano', f'${df["Price_USD"].median():,.2f}'],
        ['Desviaci√≥n Est√°ndar', f'${df["Price_USD"].std():,.2f}'],
        ['Ventas Totales', f'{df["Sales_Volume"].sum():,}'],
        ['Modelos √önicos', f'{df["Model"].nunique()}'],
        ['Regiones', f'{df["Region"].nunique()}'],
        ['Rango de A√±os', f'{df["Year"].min()}-{df["Year"].max()}'],
    ]

    table = ax5.table(cellText=stats_data, cellLoc='left', loc='center',
                     colWidths=[0.5, 0.5])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)

    # Estilo de la tabla
    for i in range(len(stats_data)):
        if i == 0:
            table[(i, 0)].set_facecolor('#2E86AB')
            table[(i, 1)].set_facecolor('#2E86AB')
            table[(i, 0)].set_text_props(weight='bold', color='white')
            table[(i, 1)].set_text_props(weight='bold', color='white')
        elif i % 2 == 0:
            table[(i, 0)].set_facecolor('#E8E8E8')
            table[(i, 1)].set_facecolor('#E8E8E8')

    ax5.set_title('ESTAD√çSTICAS CLAVE DEL DATASET', fontsize=14, fontweight='bold', pad=20)

    # Panel 6: Distribuci√≥n de combustibles
    ax6 = fig.add_subplot(gs[3, 2:4])
    fuel_counts = df['Fuel_Type'].value_counts()
    wedges, texts, autotexts = ax6.pie(fuel_counts.values, labels=fuel_counts.index,
                                        autopct='%1.1f%%', startangle=90,
                                        colors=colors_primary,
                                        textprops={'fontsize': 10, 'weight': 'bold'})
    ax6.set_title('DISTRIBUCI√ìN POR TIPO DE COMBUSTIBLE', fontsize=14, fontweight='bold')

    fig.suptitle('RESUMEN ESTAD√çSTICO VISUAL COMPLETO - BMW Sales Data (2010-2024)',
                 fontsize=18, fontweight='bold', y=0.98)
    plt.savefig('15_resumen_estadistico_completo.png', dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print("\n‚úÖ Visualizaciones 14-15 completadas!")
    print("\n" + "="*70)
    print("üéâ ¬°TODAS LAS VISUALIZACIONES HAN SIDO GENERADAS EXITOSAMENTE!")
    print("="*70)
    print("\nüìÅ Archivos generados (15 visualizaciones profesionales):")
    print("   01. 01_dashboard_exploratorio.png")
    print("   02. 02_matriz_correlacion_avanzada.png")
    print("   03. 03_analisis_temporal_avanzado.png")
    print("   04. 04_segmentacion_mercado.png")
    print("   05. 05_analisis_geografico.png")
    print("   06. 06_analisis_modelos.png")
    print("   07. 07_distribuciones_estadisticas.png")
    print("   08. 08_pairplot_multivariado.png")
    print("   09. 09_clustering_kmeans.png")
    print("   10. 10_regresion_lineal.png")
    print("   11. 11_dashboard_ejecutivo.png")
    print("   12. 12_analisis_outliers.png")
    print("   13. 13_composicion_proporciones.png")
    print("   14. 14_analisis_comparativo.png")
    print("   15. 15_resumen_estadistico_completo.png")
    print("\nüí° Todas las im√°genes est√°n en alta resoluci√≥n (300 DPI)")
    print("üìä Listas para presentaciones, reportes y publicaciones")
    print("="*70)


# =============================================================================
# COMPARACI√ìN: MANUAL VS PROFESIONAL
# =============================================================================

def comparacion_metodos(df):
    """Compara m√©todos manuales vs librer√≠as profesionales."""
    print("\n" + "="*70)
    print("üìä COMPARACI√ìN: M√©todos Manuales vs Librer√≠as Profesionales")
    print("="*70)

    import time

    # Calcular promedio
    print("\n--- C√°lculo de Promedio ---")

    # M√©todo manual
    start = time.time()
    suma = 0
    for precio in df['Price_USD']:
        suma += precio
    promedio_manual = suma / len(df)
    tiempo_manual = time.time() - start

    # M√©todo pandas
    start = time.time()
    promedio_pandas = df['Price_USD'].mean()
    tiempo_pandas = time.time() - start

    # M√©todo numpy
    start = time.time()
    promedio_numpy = np.mean(df['Price_USD'].values)
    tiempo_numpy = time.time() - start

    print(f"  M√©todo Manual: ${promedio_manual:,.2f} (Tiempo: {tiempo_manual*1000:.4f} ms)")
    print(f"  Pandas .mean(): ${promedio_pandas:,.2f} (Tiempo: {tiempo_pandas*1000:.4f} ms)")
    print(f"  NumPy np.mean(): ${promedio_numpy:,.2f} (Tiempo: {tiempo_numpy*1000:.4f} ms)")
    print(f"  ‚ö° Aceleraci√≥n: {tiempo_manual/tiempo_numpy:.1f}x m√°s r√°pido con NumPy")

    # Ventajas de librer√≠as profesionales
    print("\n--- Ventajas de Librer√≠as Profesionales ---")
    print("  ‚úÖ Pandas:")
    print("     ‚Ä¢ Manejo eficiente de grandes datasets")
    print("     ‚Ä¢ Operaciones vectorizadas (m√°s r√°pidas)")
    print("     ‚Ä¢ Funciones integradas para an√°lisis")
    print("     ‚Ä¢ Manejo autom√°tico de valores nulos")
    print("     ‚Ä¢ Integraci√≥n con otras librer√≠as")

    print("\n  ‚úÖ NumPy:")
    print("     ‚Ä¢ Operaciones matem√°ticas optimizadas")
    print("     ‚Ä¢ Arrays multidimensionales eficientes")
    print("     ‚Ä¢ Funciones estad√≠sticas r√°pidas")
    print("     ‚Ä¢ Base para otras librer√≠as cient√≠ficas")

    print("\n  ‚úÖ SciPy:")
    print("     ‚Ä¢ Pruebas estad√≠sticas avanzadas")
    print("     ‚Ä¢ Distribuciones de probabilidad")
    print("     ‚Ä¢ Optimizaci√≥n y √°lgebra lineal")
    print("     ‚Ä¢ M√©todos cient√≠ficos validados")

    print("\n  ‚úÖ Scikit-Learn:")
    print("     ‚Ä¢ Algoritmos de machine learning")
    print("     ‚Ä¢ Preprocesamiento de datos")
    print("     ‚Ä¢ Validaci√≥n de modelos")
    print("     ‚Ä¢ Escalabilidad y rendimiento")

    print("\n  ‚úÖ Matplotlib/Seaborn:")
    print("     ‚Ä¢ Visualizaciones profesionales")
    print("     ‚Ä¢ Gr√°ficos estad√≠sticos avanzados")
    print("     ‚Ä¢ Personalizaci√≥n completa")
    print("     ‚Ä¢ Exportaci√≥n de alta calidad")


# =============================================================================
# EJERCICIOS PROPUESTOS
# =============================================================================

def mostrar_ejercicios():
    """Muestra ejercicios propuestos para practicar con librer√≠as profesionales."""
    print("\n" + "="*70)
    print("üìù EJERCICIOS PROPUESTOS - LIBRER√çAS PROFESIONALES")
    print("="*70)

    print("\nüìö Objetivo: Aprender a usar pandas, numpy, scipy, matplotlib,")
    print("   seaborn y scikit-learn para an√°lisis de datos profesional.")

    ejercicios = [
        {
            "nivel": "B√°sico - Pandas & NumPy",
            "emoji": "üü¢",
            "ejercicios": [
                "1. Usa df.groupby() para calcular el precio promedio por modelo",
                "2. Filtra veh√≠culos con df[df['Year'] > 2020] y calcula estad√≠sticas",
                "3. Crea una nueva columna 'Price_per_KM' usando operaciones vectorizadas",
                "4. Usa pd.crosstab() para analizar Region √ó Fuel_Type",
                "5. Calcula percentiles con np.percentile() para diferentes columnas",
                "6. Usa df.sort_values() para ordenar por m√∫ltiples columnas",
                "7. Aplica df.pivot_table() para crear tabla resumen",
                "8. Usa np.where() para crear categor√≠as de precio (bajo/medio/alto)"
            ]
        },
        {
            "nivel": "Intermedio - SciPy & Estad√≠stica",
            "emoji": "üü°",
            "ejercicios": [
                "1. Realiza un test t de Student para comparar precios entre dos regiones",
                "2. Calcula intervalos de confianza para diferentes variables",
                "3. Usa stats.pearsonr() para correlaciones con p-valores",
                "4. Aplica test de normalidad a diferentes columnas num√©ricas",
                "5. Realiza ANOVA para comparar precios entre m√∫ltiples grupos",
                "6. Calcula la distribuci√≥n de probabilidad de los precios",
                "7. Usa stats.zscore() para detectar outliers",
                "8. Aplica transformaciones (log, sqrt) y eval√∫a normalidad"
            ]
        },
        {
            "nivel": "Avanzado - Machine Learning",
            "emoji": "üî¥",
            "ejercicios": [
                "1. Entrena un modelo de regresi√≥n para predecir Sales_Volume",
                "2. Aplica K-Means con diferentes valores de k y eval√∫a con elbow method",
                "3. Usa PCA para reducir dimensionalidad y visualiza en 2D",
                "4. Implementa validaci√≥n cruzada con cross_val_score",
                "5. Crea un pipeline de preprocesamiento + modelo",
                "6. Usa GridSearchCV para optimizar hiperpar√°metros",
                "7. Implementa Random Forest y compara con regresi√≥n lineal",
                "8. Aplica DBSCAN para clustering basado en densidad"
            ]
        },
        {
            "nivel": "Experto - Visualizaci√≥n & An√°lisis Completo",
            "emoji": "üèÜ",
            "ejercicios": [
                "1. Crea un dashboard completo con subplots (2x3 gr√°ficos)",
                "2. Usa seaborn.pairplot() para visualizar relaciones m√∫ltiples",
                "3. Crea gr√°ficos interactivos con plotly",
                "4. Implementa an√°lisis de series temporales con tendencias",
                "5. Crea heatmaps animados para evoluci√≥n temporal",
                "6. Dise√±a un informe autom√°tico con todas las m√©tricas clave",
                "7. Implementa an√°lisis de cohortes por a√±o de venta",
                "8. Crea visualizaciones 3D con matplotlib"
            ]
        }
    ]

    for grupo in ejercicios:
        print(f"\n{grupo['emoji']} {grupo['nivel']}:")
        for ejercicio in grupo['ejercicios']:
            print(f"   {ejercicio}")

    print("\n" + "="*70)
    print("üí° Tips:")
    print("   ‚Ä¢ Consulta la documentaci√≥n oficial de cada librer√≠a")
    print("   ‚Ä¢ Experimenta con diferentes par√°metros")
    print("   ‚Ä¢ Compara resultados entre diferentes m√©todos")
    print("   ‚Ä¢ Visualiza siempre que sea posible")
    print("   ‚Ä¢ Valida tus resultados con m√∫ltiples enfoques")
    print("="*70)


# =============================================================================
# MEN√ö PRINCIPAL
# =============================================================================

def mostrar_menu():
    """Muestra el men√∫ principal."""
    print("\n" + "="*70)
    print("üéì ACTIVIDAD 9: AN√ÅLISIS DE DATOS CON LIBRER√çAS PROFESIONALES")
    print("="*70)

    print("\nSelecciona un nivel de an√°lisis:")
    print("\n  1Ô∏è‚É£  Nivel 1: Estad√≠stica B√°sica")
    print("      (Pandas & NumPy)")
    print("\n  2Ô∏è‚É£  Nivel 2: Estad√≠stica Avanzada")
    print("      (SciPy & Pruebas Estad√≠sticas)")
    print("\n  3Ô∏è‚É£  Nivel 3: Ciencia de Datos")
    print("      (Scikit-Learn & Machine Learning)")
    print("\n  4Ô∏è‚É£  Bonus: Visualizaciones Profesionales")
    print("      (Matplotlib & Seaborn)")
    print("\n  5Ô∏è‚É£  Comparaci√≥n: Manual vs Profesional")
    print("\n  6Ô∏è‚É£  Ver Ejercicios Propuestos")
    print("\n  7Ô∏è‚É£  Ejecutar An√°lisis Completo")
    print("\n  8Ô∏è‚É£  Informaci√≥n del Dataset")
    print("\n  0Ô∏è‚É£  Salir")

    print("\n" + "="*70)


def main():
    """Funci√≥n principal del programa."""
    print("üåü" * 35)
    print("   AN√ÅLISIS DE DATOS CON LIBRER√çAS PROFESIONALES")
    print("üåü" * 35)

    print("\nüìö Librer√≠as utilizadas:")
    print("   ‚Ä¢ pandas - Manipulaci√≥n de datos")
    print("   ‚Ä¢ numpy - Computaci√≥n num√©rica")
    print("   ‚Ä¢ scipy - Estad√≠stica avanzada")
    print("   ‚Ä¢ matplotlib - Visualizaciones")
    print("   ‚Ä¢ seaborn - Gr√°ficos estad√≠sticos")
    print("   ‚Ä¢ scikit-learn - Machine Learning")

    # Cargar datos
    print("\nüìÇ Cargando datos...")
    df = cargar_datos()

    if df is None:
        print("‚ùå No se pudo cargar el archivo. Programa terminado.")
        return

    while True:
        mostrar_menu()
        opcion = input("\nüëâ Ingresa tu opci√≥n: ").strip()

        if opcion == "1":
            estadistica_basica_pandas(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "2":
            estadistica_avanzada_scipy(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "3":
            ciencia_datos_sklearn(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "4":
            crear_visualizaciones(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "5":
            comparacion_metodos(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "6":
            mostrar_ejercicios()
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "7":
            print("\nüöÄ Ejecutando an√°lisis completo...\n")
            estadistica_basica_pandas(df)
            input("\n‚è∏Ô∏è  Presiona Enter para continuar...")
            estadistica_avanzada_scipy(df)
            input("\n‚è∏Ô∏è  Presiona Enter para continuar...")
            ciencia_datos_sklearn(df)
            input("\n‚è∏Ô∏è  Presiona Enter para continuar...")
            crear_visualizaciones(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "8":
            mostrar_info_dataset(df)
            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        elif opcion == "0":
            print("\n¬°Hasta luego! üëã")
            print("üí° Recuerda: Las librer√≠as profesionales hacen tu c√≥digo m√°s")
            print("   eficiente, legible y mantenible. ¬°Sigue practicando!")
            break

        else:
            print("\n‚ùå Opci√≥n no v√°lida. Por favor, selecciona una opci√≥n del men√∫.")


if __name__ == "__main__":
    main()

