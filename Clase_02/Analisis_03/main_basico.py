"""
Script Profesional de An√°lisis de Calidad de Agua
Autor: Experto en An√°lisis de Datos Ambientales
Descripci√≥n: An√°lisis completo de datos de calidad de agua subterr√°nea
             con implementaciones manuales de estad√≠stica aplicada
Niveles: B√°sico, Medio, Avanzado y Ciencia de Datos
"""

import csv
import math
from collections import defaultdict
from typing import List, Dict, Tuple, Any
import os


# ============================================================================
# M√ìDULO 1: FUNCIONES ESTAD√çSTICAS MANUALES
# ============================================================================

class EstadisticaManual:
    """Implementaci√≥n manual de funciones estad√≠sticas fundamentales"""
    
    @staticmethod
    def media(datos: List[float]) -> float:
        """Calcula la media aritm√©tica"""
        if not datos:
            return 0.0
        return sum(datos) / len(datos)
    
    @staticmethod
    def mediana(datos: List[float]) -> float:
        """Calcula la mediana"""
        if not datos:
            return 0.0
        datos_ordenados = sorted(datos)
        n = len(datos_ordenados)
        if n % 2 == 0:
            return (datos_ordenados[n//2 - 1] + datos_ordenados[n//2]) / 2
        return datos_ordenados[n//2]
    
    @staticmethod
    def moda(datos: List[float]) -> float:
        """Calcula la moda"""
        if not datos:
            return 0.0
        frecuencias = {}
        for valor in datos:
            frecuencias[valor] = frecuencias.get(valor, 0) + 1
        return max(frecuencias, key=frecuencias.get)
    
    @staticmethod
    def varianza(datos: List[float], muestral: bool = True) -> float:
        """Calcula la varianza (muestral o poblacional)"""
        if len(datos) < 2:
            return 0.0
        media = EstadisticaManual.media(datos)
        suma_cuadrados = sum((x - media) ** 2 for x in datos)
        divisor = len(datos) - 1 if muestral else len(datos)
        return suma_cuadrados / divisor
    
    @staticmethod
    def desviacion_estandar(datos: List[float], muestral: bool = True) -> float:
        """Calcula la desviaci√≥n est√°ndar"""
        return math.sqrt(EstadisticaManual.varianza(datos, muestral))
    
    @staticmethod
    def coeficiente_variacion(datos: List[float]) -> float:
        """Calcula el coeficiente de variaci√≥n (CV%)"""
        media = EstadisticaManual.media(datos)
        if media == 0:
            return 0.0
        return (EstadisticaManual.desviacion_estandar(datos) / media) * 100
    
    @staticmethod
    def percentil(datos: List[float], p: float) -> float:
        """Calcula el percentil p (0-100)"""
        if not datos:
            return 0.0
        datos_ordenados = sorted(datos)
        k = (len(datos_ordenados) - 1) * (p / 100)
        f = math.floor(k)
        c = math.ceil(k)
        if f == c:
            return datos_ordenados[int(k)]
        d0 = datos_ordenados[int(f)] * (c - k)
        d1 = datos_ordenados[int(c)] * (k - f)
        return d0 + d1
    
    @staticmethod
    def rango_intercuartil(datos: List[float]) -> float:
        """Calcula el rango intercuart√≠lico (IQR)"""
        q1 = EstadisticaManual.percentil(datos, 25)
        q3 = EstadisticaManual.percentil(datos, 75)
        return q3 - q1
    
    @staticmethod
    def asimetria(datos: List[float]) -> float:
        """Calcula el coeficiente de asimetr√≠a (skewness)"""
        if len(datos) < 3:
            return 0.0
        n = len(datos)
        media = EstadisticaManual.media(datos)
        desv = EstadisticaManual.desviacion_estandar(datos)
        if desv == 0:
            return 0.0
        suma_cubos = sum(((x - media) / desv) ** 3 for x in datos)
        return (n / ((n - 1) * (n - 2))) * suma_cubos
    
    @staticmethod
    def curtosis(datos: List[float]) -> float:
        """Calcula el coeficiente de curtosis (kurtosis)"""
        if len(datos) < 4:
            return 0.0
        n = len(datos)
        media = EstadisticaManual.media(datos)
        desv = EstadisticaManual.desviacion_estandar(datos)
        if desv == 0:
            return 0.0
        suma_cuartos = sum(((x - media) / desv) ** 4 for x in datos)
        return ((n * (n + 1)) / ((n - 1) * (n - 2) * (n - 3))) * suma_cuartos - \
               (3 * (n - 1) ** 2) / ((n - 2) * (n - 3))
    
    @staticmethod
    def covarianza(x: List[float], y: List[float]) -> float:
        """Calcula la covarianza entre dos variables"""
        if len(x) != len(y) or len(x) < 2:
            return 0.0
        media_x = EstadisticaManual.media(x)
        media_y = EstadisticaManual.media(y)
        return sum((x[i] - media_x) * (y[i] - media_y) for i in range(len(x))) / (len(x) - 1)
    
    @staticmethod
    def correlacion_pearson(x: List[float], y: List[float]) -> float:
        """Calcula el coeficiente de correlaci√≥n de Pearson"""
        if len(x) != len(y) or len(x) < 2:
            return 0.0
        cov = EstadisticaManual.covarianza(x, y)
        desv_x = EstadisticaManual.desviacion_estandar(x)
        desv_y = EstadisticaManual.desviacion_estandar(y)
        if desv_x == 0 or desv_y == 0:
            return 0.0
        return cov / (desv_x * desv_y)
    
    @staticmethod
    def regresion_lineal(x: List[float], y: List[float]) -> Tuple[float, float, float]:
        """
        Calcula regresi√≥n lineal simple: y = a + bx
        Retorna: (pendiente, intercepto, r_cuadrado)
        """
        if len(x) != len(y) or len(x) < 2:
            return 0.0, 0.0, 0.0
        
        n = len(x)
        media_x = EstadisticaManual.media(x)
        media_y = EstadisticaManual.media(y)
        
        # Pendiente
        numerador = sum((x[i] - media_x) * (y[i] - media_y) for i in range(n))
        denominador = sum((x[i] - media_x) ** 2 for i in range(n))
        
        if denominador == 0:
            return 0.0, media_y, 0.0
        
        pendiente = numerador / denominador
        intercepto = media_y - pendiente * media_x
        
        # R cuadrado
        r = EstadisticaManual.correlacion_pearson(x, y)
        r_cuadrado = r ** 2
        
        return pendiente, intercepto, r_cuadrado
    
    @staticmethod
    def normalizar_zscore(datos: List[float]) -> List[float]:
        """Normaliza datos usando Z-score"""
        media = EstadisticaManual.media(datos)
        desv = EstadisticaManual.desviacion_estandar(datos)
        if desv == 0:
            return [0.0] * len(datos)
        return [(x - media) / desv for x in datos]
    
    @staticmethod
    def normalizar_minmax(datos: List[float]) -> List[float]:
        """Normaliza datos al rango [0, 1]"""
        minimo = min(datos)
        maximo = max(datos)
        rango = maximo - minimo
        if rango == 0:
            return [0.5] * len(datos)
        return [(x - minimo) / rango for x in datos]


# ============================================================================
# M√ìDULO 2: CARGA Y PROCESAMIENTO DE DATOS
# ============================================================================

class CargadorDatos:
    """Maneja la carga y procesamiento inicial de datos"""
    
    def __init__(self, directorio: str = "samples"):
        self.directorio = directorio
        self.datos_combinados = []
        self.columnas = []
        
    def cargar_archivos_csv(self) -> List[Dict[str, Any]]:
        """Carga todos los archivos CSV de calidad de agua"""
        archivos = [
            "ground_water_quality_2018_post.csv",
            "ground_water_quality_2019_post.csv",
            "ground_water_quality_2020_post.csv"
        ]
        
        datos_totales = []
        
        for archivo in archivos:
            ruta = os.path.join(self.directorio, archivo)
            if not os.path.exists(ruta):
                print(f"‚ö†Ô∏è  Archivo no encontrado: {ruta}")
                continue
                
            with open(ruta, 'r', encoding='utf-8') as f:
                lector = csv.DictReader(f)
                for fila in lector:
                    # Extraer a√±o del nombre del archivo
                    a√±o = archivo.split('_')[3]
                    fila['a√±o'] = a√±o
                    datos_totales.append(fila)
        
        if datos_totales:
            self.columnas = list(datos_totales[0].keys())
        
        self.datos_combinados = datos_totales
        print(f"‚úì Cargados {len(datos_totales)} registros de {len(archivos)} archivos")
        return datos_totales
    
    def obtener_columnas_numericas(self) -> List[str]:
        """Identifica columnas num√©ricas"""
        columnas_numericas = []
        if not self.datos_combinados:
            return columnas_numericas
        
        muestra = self.datos_combinados[0]
        for columna in muestra.keys():
            if columna in ['sno', 'district', 'mandal', 'village', 'season', 
                          'Classification', 'Classification.1', 'a√±o']:
                continue
            try:
                float(muestra[columna])
                columnas_numericas.append(columna)
            except (ValueError, TypeError):
                pass
        
        return columnas_numericas
    
    def extraer_columna(self, nombre_columna: str, limpiar_nulos: bool = True) -> List[float]:
        """Extrae una columna como lista de floats"""
        valores = []
        for fila in self.datos_combinados:
            try:
                valor = float(fila.get(nombre_columna, 0))
                if not (limpiar_nulos and (math.isnan(valor) or valor == 0)):
                    valores.append(valor)
            except (ValueError, TypeError):
                if not limpiar_nulos:
                    valores.append(0.0)
        return valores


# ============================================================================
# M√ìDULO 3: AN√ÅLISIS B√ÅSICO
# ============================================================================

class AnalisisBasico:
    """An√°lisis estad√≠stico descriptivo b√°sico"""

    def __init__(self, cargador: CargadorDatos):
        self.cargador = cargador
        self.stats = EstadisticaManual()

    def resumen_general(self):
        """Genera un resumen general del dataset"""
        print("\n" + "="*80)
        print("AN√ÅLISIS B√ÅSICO - RESUMEN GENERAL DEL DATASET")
        print("="*80)

        total_registros = len(self.cargador.datos_combinados)
        print(f"\nüìä Total de registros: {total_registros}")

        # Distribuci√≥n por a√±o
        a√±os = {}
        for fila in self.cargador.datos_combinados:
            a√±o = fila.get('a√±o', 'Desconocido')
            a√±os[a√±o] = a√±os.get(a√±o, 0) + 1

        print("\nüìÖ Distribuci√≥n por a√±o:")
        for a√±o, cantidad in sorted(a√±os.items()):
            porcentaje = (cantidad / total_registros) * 100
            print(f"   {a√±o}: {cantidad} registros ({porcentaje:.1f}%)")

        # Distribuci√≥n por distrito
        distritos = {}
        for fila in self.cargador.datos_combinados:
            distrito = fila.get('district', 'Desconocido')
            distritos[distrito] = distritos.get(distrito, 0) + 1

        print(f"\nüó∫Ô∏è  Total de distritos: {len(distritos)}")
        print("   Top 5 distritos con m√°s muestras:")
        top_distritos = sorted(distritos.items(), key=lambda x: x[1], reverse=True)[:5]
        for distrito, cantidad in top_distritos:
            print(f"   - {distrito}: {cantidad} muestras")

        # Distribuci√≥n por clasificaci√≥n
        clasificaciones = {}
        for fila in self.cargador.datos_combinados:
            clasif = fila.get('Classification', 'Desconocido')
            clasificaciones[clasif] = clasificaciones.get(clasif, 0) + 1

        print(f"\nüíß Distribuci√≥n por clasificaci√≥n de calidad:")
        for clasif, cantidad in sorted(clasificaciones.items(), key=lambda x: x[1], reverse=True):
            porcentaje = (cantidad / total_registros) * 100
            print(f"   {clasif}: {cantidad} ({porcentaje:.1f}%)")

    def estadisticas_descriptivas(self, columna: str):
        """Calcula estad√≠sticas descriptivas para una columna"""
        datos = self.cargador.extraer_columna(columna)

        if not datos:
            print(f"‚ö†Ô∏è  No hay datos disponibles para {columna}")
            return

        print(f"\n{'‚îÄ'*80}")
        print(f"üìà ESTAD√çSTICAS DESCRIPTIVAS: {columna}")
        print(f"{'‚îÄ'*80}")

        print(f"\nüî¢ Medidas de tendencia central:")
        print(f"   Media:              {self.stats.media(datos):.4f}")
        print(f"   Mediana:            {self.stats.mediana(datos):.4f}")
        print(f"   Moda:               {self.stats.moda(datos):.4f}")

        print(f"\nüìä Medidas de dispersi√≥n:")
        print(f"   Desviaci√≥n est√°ndar: {self.stats.desviacion_estandar(datos):.4f}")
        print(f"   Varianza:            {self.stats.varianza(datos):.4f}")
        print(f"   Coef. de variaci√≥n:  {self.stats.coeficiente_variacion(datos):.2f}%")
        print(f"   Rango:               {max(datos) - min(datos):.4f}")
        print(f"   IQR:                 {self.stats.rango_intercuartil(datos):.4f}")

        print(f"\nüìè Valores extremos:")
        print(f"   M√≠nimo:              {min(datos):.4f}")
        print(f"   M√°ximo:              {max(datos):.4f}")
        print(f"   Q1 (25%):            {self.stats.percentil(datos, 25):.4f}")
        print(f"   Q2 (50%):            {self.stats.percentil(datos, 50):.4f}")
        print(f"   Q3 (75%):            {self.stats.percentil(datos, 75):.4f}")

        print(f"\nüìê Forma de la distribuci√≥n:")
        print(f"   Asimetr√≠a (Skewness): {self.stats.asimetria(datos):.4f}")
        print(f"   Curtosis (Kurtosis):  {self.stats.curtosis(datos):.4f}")

        # Interpretaci√≥n
        asimetria = self.stats.asimetria(datos)
        if asimetria > 0.5:
            print(f"   ‚Üí Distribuci√≥n sesgada a la derecha (cola larga hacia valores altos)")
        elif asimetria < -0.5:
            print(f"   ‚Üí Distribuci√≥n sesgada a la izquierda (cola larga hacia valores bajos)")
        else:
            print(f"   ‚Üí Distribuci√≥n aproximadamente sim√©trica")

    def analisis_completo_parametros(self):
        """Realiza an√°lisis descriptivo de todos los par√°metros qu√≠micos"""
        print("\n" + "="*80)
        print("AN√ÅLISIS COMPLETO DE PAR√ÅMETROS QU√çMICOS")
        print("="*80)

        parametros = ['pH', 'E.C', 'TDS', 'CO3', 'HCO3', 'Cl', 'F', 'NO3 ',
                     'SO4', 'Na', 'K', 'Ca', 'Mg', 'T.H', 'SAR']

        for parametro in parametros:
            self.estadisticas_descriptivas(parametro)

    def calidad_por_distrito(self):
        """Analiza la calidad del agua por distrito"""
        print("\n" + "="*80)
        print("AN√ÅLISIS DE CALIDAD POR DISTRITO")
        print("="*80)

        # Agrupar por distrito
        distritos_data = defaultdict(lambda: {'TDS': [], 'pH': [], 'clasificaciones': []})

        for fila in self.cargador.datos_combinados:
            distrito = fila.get('district', 'Desconocido')
            try:
                tds = float(fila.get('TDS', 0))
                ph = float(fila.get('pH', 0))
                if tds > 0 and ph > 0:
                    distritos_data[distrito]['TDS'].append(tds)
                    distritos_data[distrito]['pH'].append(ph)
                    distritos_data[distrito]['clasificaciones'].append(fila.get('Classification', ''))
            except (ValueError, TypeError):
                pass

        # Calcular promedios
        resultados = []
        for distrito, datos in distritos_data.items():
            if datos['TDS']:
                tds_promedio = self.stats.media(datos['TDS'])
                ph_promedio = self.stats.media(datos['pH'])
                n_muestras = len(datos['TDS'])
                resultados.append((distrito, tds_promedio, ph_promedio, n_muestras))

        # Ordenar por TDS promedio
        resultados.sort(key=lambda x: x[1], reverse=True)

        print(f"\n{'Distrito':<25} {'TDS Prom.':<12} {'pH Prom.':<10} {'Muestras':<10}")
        print("‚îÄ" * 80)
        for distrito, tds, ph, n in resultados[:15]:  # Top 15
            print(f"{distrito:<25} {tds:>10.2f}   {ph:>8.2f}   {n:>8}")


# ============================================================================
# M√ìDULO 4: AN√ÅLISIS MEDIO
# ============================================================================

class AnalisisMedio:
    """An√°lisis de correlaciones, distribuciones y detecci√≥n de outliers"""

    def __init__(self, cargador: CargadorDatos):
        self.cargador = cargador
        self.stats = EstadisticaManual()

    def matriz_correlacion(self, parametros: List[str] = None):
        """Calcula matriz de correlaci√≥n entre par√°metros"""
        if parametros is None:
            parametros = ['pH', 'E.C', 'TDS', 'Cl', 'Na', 'Ca', 'Mg', 'T.H', 'SAR']

        print("\n" + "="*80)
        print("MATRIZ DE CORRELACI√ìN DE PEARSON")
        print("="*80)

        # Extraer datos
        datos_parametros = {}
        for param in parametros:
            datos_parametros[param] = self.cargador.extraer_columna(param)

        # Calcular correlaciones
        print(f"\n{'Par√°metro':<10}", end="")
        for param in parametros:
            print(f"{param:>8}", end="")
        print()
        print("‚îÄ" * (10 + 8 * len(parametros)))

        for param1 in parametros:
            print(f"{param1:<10}", end="")
            for param2 in parametros:
                if len(datos_parametros[param1]) > 0 and len(datos_parametros[param2]) > 0:
                    # Asegurar misma longitud
                    min_len = min(len(datos_parametros[param1]), len(datos_parametros[param2]))
                    corr = self.stats.correlacion_pearson(
                        datos_parametros[param1][:min_len],
                        datos_parametros[param2][:min_len]
                    )
                    print(f"{corr:>8.3f}", end="")
                else:
                    print(f"{'N/A':>8}", end="")
            print()

        # Identificar correlaciones fuertes
        print("\nüîç Correlaciones significativas (|r| > 0.7):")
        for i, param1 in enumerate(parametros):
            for j, param2 in enumerate(parametros):
                if i < j:  # Evitar duplicados
                    min_len = min(len(datos_parametros[param1]), len(datos_parametros[param2]))
                    if min_len > 0:
                        corr = self.stats.correlacion_pearson(
                            datos_parametros[param1][:min_len],
                            datos_parametros[param2][:min_len]
                        )
                        if abs(corr) > 0.7:
                            tipo = "positiva" if corr > 0 else "negativa"
                            print(f"   {param1} ‚Üî {param2}: r = {corr:.3f} ({tipo})")

    def detectar_outliers_iqr(self, columna: str):
        """Detecta outliers usando el m√©todo IQR"""
        datos = self.cargador.extraer_columna(columna)

        if not datos:
            print(f"‚ö†Ô∏è  No hay datos para {columna}")
            return

        print(f"\n{'‚îÄ'*80}")
        print(f"üîç DETECCI√ìN DE OUTLIERS: {columna} (M√©todo IQR)")
        print(f"{'‚îÄ'*80}")

        q1 = self.stats.percentil(datos, 25)
        q3 = self.stats.percentil(datos, 75)
        iqr = q3 - q1

        limite_inferior = q1 - 1.5 * iqr
        limite_superior = q3 + 1.5 * iqr

        outliers = [x for x in datos if x < limite_inferior or x > limite_superior]
        outliers_extremos = [x for x in datos if x < q1 - 3 * iqr or x > q3 + 3 * iqr]

        print(f"\nüìä L√≠mites de detecci√≥n:")
        print(f"   Q1:                  {q1:.4f}")
        print(f"   Q3:                  {q3:.4f}")
        print(f"   IQR:                 {iqr:.4f}")
        print(f"   L√≠mite inferior:     {limite_inferior:.4f}")
        print(f"   L√≠mite superior:     {limite_superior:.4f}")

        print(f"\nüéØ Resultados:")
        print(f"   Total de datos:      {len(datos)}")
        print(f"   Outliers moderados:  {len(outliers)} ({len(outliers)/len(datos)*100:.2f}%)")
        print(f"   Outliers extremos:   {len(outliers_extremos)} ({len(outliers_extremos)/len(datos)*100:.2f}%)")

        if outliers:
            print(f"\n   Valores outliers (primeros 10):")
            for valor in sorted(outliers, reverse=True)[:10]:
                print(f"      {valor:.4f}")

    def analisis_temporal(self):
        """Analiza tendencias temporales entre a√±os"""
        print("\n" + "="*80)
        print("AN√ÅLISIS TEMPORAL (2018-2020)")
        print("="*80)

        parametros = ['pH', 'TDS', 'E.C', 'T.H', 'SAR']
        a√±os = ['2018', '2019', '2020']

        for parametro in parametros:
            print(f"\nüìà Tendencia temporal: {parametro}")
            print("‚îÄ" * 60)

            valores_por_a√±o = {}
            for a√±o in a√±os:
                valores = []
                for fila in self.cargador.datos_combinados:
                    if fila.get('a√±o') == a√±o:
                        try:
                            valor = float(fila.get(parametro, 0))
                            if valor > 0:
                                valores.append(valor)
                        except (ValueError, TypeError):
                            pass
                valores_por_a√±o[a√±o] = valores

            # Calcular estad√≠sticas por a√±o
            print(f"\n{'A√±o':<8} {'Media':<12} {'Mediana':<12} {'Desv.Est':<12} {'N':<8}")
            print("‚îÄ" * 60)

            medias = []
            for a√±o in a√±os:
                if valores_por_a√±o[a√±o]:
                    media = self.stats.media(valores_por_a√±o[a√±o])
                    mediana = self.stats.mediana(valores_por_a√±o[a√±o])
                    desv = self.stats.desviacion_estandar(valores_por_a√±o[a√±o])
                    n = len(valores_por_a√±o[a√±o])
                    medias.append(media)
                    print(f"{a√±o:<8} {media:<12.4f} {mediana:<12.4f} {desv:<12.4f} {n:<8}")

            # Calcular tendencia
            if len(medias) == 3:
                x = [0, 1, 2]  # A√±os codificados
                pendiente, intercepto, r2 = self.stats.regresion_lineal(x, medias)

                print(f"\n   Tendencia lineal:")
                print(f"   Pendiente: {pendiente:.4f} (cambio anual)")
                print(f"   R¬≤: {r2:.4f}")

                if abs(pendiente) > 0.01:
                    direccion = "incremento" if pendiente > 0 else "disminuci√≥n"
                    print(f"   ‚Üí Se observa {direccion} de {abs(pendiente):.4f} unidades por a√±o")
                else:
                    print(f"   ‚Üí Valores relativamente estables en el tiempo")

    def analisis_distribucion(self, columna: str):
        """Analiza la distribuci√≥n de una variable"""
        datos = self.cargador.extraer_columna(columna)

        if not datos:
            return

        print(f"\n{'‚îÄ'*80}")
        print(f"üìä AN√ÅLISIS DE DISTRIBUCI√ìN: {columna}")
        print(f"{'‚îÄ'*80}")

        # Crear histograma manual
        n_bins = 10
        minimo = min(datos)
        maximo = max(datos)
        ancho_bin = (maximo - minimo) / n_bins

        bins = [0] * n_bins
        for valor in datos:
            bin_idx = int((valor - minimo) / ancho_bin)
            if bin_idx >= n_bins:
                bin_idx = n_bins - 1
            bins[bin_idx] += 1

        print(f"\nüìä Histograma (n={len(datos)}):")
        print(f"{'Rango':<25} {'Frecuencia':<12} {'Gr√°fico'}")
        print("‚îÄ" * 80)

        max_freq = max(bins)
        for i, freq in enumerate(bins):
            inicio = minimo + i * ancho_bin
            fin = inicio + ancho_bin
            barra = '‚ñà' * int((freq / max_freq) * 40)
            print(f"{inicio:>10.2f} - {fin:<10.2f} {freq:<12} {barra}")

        # Test de normalidad (aproximado usando asimetr√≠a y curtosis)
        asimetria = self.stats.asimetria(datos)
        curtosis = self.stats.curtosis(datos)

        print(f"\nüî¨ Evaluaci√≥n de normalidad:")
        print(f"   Asimetr√≠a: {asimetria:.4f}")
        print(f"   Curtosis:  {curtosis:.4f}")

        if abs(asimetria) < 0.5 and abs(curtosis) < 1:
            print(f"   ‚Üí La distribuci√≥n es aproximadamente normal")
        elif abs(asimetria) >= 0.5:
            print(f"   ‚Üí La distribuci√≥n presenta asimetr√≠a significativa")
        else:
            print(f"   ‚Üí La distribuci√≥n presenta colas pesadas/ligeras")


# ============================================================================
# M√ìDULO 5: AN√ÅLISIS AVANZADO
# ============================================================================

class AnalisisAvanzado:
    """An√°lisis multivariado, PCA manual, clustering y an√°lisis espacial"""

    def __init__(self, cargador: CargadorDatos):
        self.cargador = cargador
        self.stats = EstadisticaManual()

    def pca_manual(self, parametros: List[str] = None, n_componentes: int = 3):
        """
        Implementaci√≥n manual de PCA (An√°lisis de Componentes Principales)
        Simplificado usando m√©todo de potencias para eigenvalores
        """
        if parametros is None:
            parametros = ['pH', 'E.C', 'TDS', 'Na', 'Ca', 'Mg', 'T.H']

        print("\n" + "="*80)
        print("AN√ÅLISIS DE COMPONENTES PRINCIPALES (PCA)")
        print("="*80)

        # Extraer y normalizar datos
        datos_matriz = []
        for param in parametros:
            datos = self.cargador.extraer_columna(param)
            datos_norm = self.stats.normalizar_zscore(datos)
            datos_matriz.append(datos_norm)

        n_vars = len(parametros)
        n_obs = len(datos_matriz[0])

        print(f"\nüìä Configuraci√≥n:")
        print(f"   Variables: {n_vars}")
        print(f"   Observaciones: {n_obs}")
        print(f"   Componentes a extraer: {n_componentes}")

        # Calcular matriz de covarianza
        print(f"\nüî¢ Matriz de covarianza:")
        cov_matriz = []
        for i in range(n_vars):
            fila = []
            for j in range(n_vars):
                cov = self.stats.covarianza(datos_matriz[i], datos_matriz[j])
                fila.append(cov)
            cov_matriz.append(fila)

        # Mostrar matriz de covarianza
        print(f"\n{'':>10}", end="")
        for param in parametros:
            print(f"{param:>10}", end="")
        print()
        for i, param in enumerate(parametros):
            print(f"{param:>10}", end="")
            for j in range(n_vars):
                print(f"{cov_matriz[i][j]:>10.4f}", end="")
            print()

        # Calcular varianza total
        varianza_total = sum(cov_matriz[i][i] for i in range(n_vars))
        print(f"\n   Varianza total: {varianza_total:.4f}")

        # Aproximaci√≥n de componentes principales (simplificada)
        # En un PCA completo se calcular√≠an eigenvalores y eigenvectores
        # Aqu√≠ usamos una aproximaci√≥n basada en la varianza de cada variable
        print(f"\nüìà Contribuci√≥n de varianza por variable:")
        varianzas = [(parametros[i], cov_matriz[i][i]) for i in range(n_vars)]
        varianzas.sort(key=lambda x: x[1], reverse=True)

        varianza_acum = 0
        for i, (param, var) in enumerate(varianzas):
            prop = (var / varianza_total) * 100
            varianza_acum += prop
            print(f"   PC{i+1} ({param}): {prop:.2f}% (Acumulado: {varianza_acum:.2f}%)")

    def clustering_kmeans_manual(self, parametros: List[str] = None, k: int = 3, max_iter: int = 50):
        """
        Implementaci√≥n manual de K-Means clustering
        """
        if parametros is None:
            parametros = ['TDS', 'T.H', 'SAR']

        print("\n" + "="*80)
        print(f"CLUSTERING K-MEANS (k={k})")
        print("="*80)

        # Extraer y normalizar datos
        datos_matriz = []
        for param in parametros:
            datos = self.cargador.extraer_columna(param)
            datos_norm = self.stats.normalizar_minmax(datos)
            datos_matriz.append(datos_norm)

        n_vars = len(parametros)
        n_obs = len(datos_matriz[0])

        print(f"\nüìä Configuraci√≥n:")
        print(f"   Variables: {', '.join(parametros)}")
        print(f"   Observaciones: {n_obs}")
        print(f"   Clusters (k): {k}")

        # Transponer matriz para tener observaciones como filas
        observaciones = [[datos_matriz[j][i] for j in range(n_vars)] for i in range(n_obs)]

        # Inicializar centroides aleatoriamente
        import random
        random.seed(42)
        centroides = random.sample(observaciones, k)

        # Algoritmo K-Means
        for iteracion in range(max_iter):
            # Asignar cada punto al centroide m√°s cercano
            asignaciones = []
            for obs in observaciones:
                distancias = []
                for centroide in centroides:
                    dist = math.sqrt(sum((obs[i] - centroide[i])**2 for i in range(n_vars)))
                    distancias.append(dist)
                asignaciones.append(distancias.index(min(distancias)))

            # Recalcular centroides
            nuevos_centroides = []
            for cluster_id in range(k):
                puntos_cluster = [observaciones[i] for i in range(n_obs) if asignaciones[i] == cluster_id]
                if puntos_cluster:
                    nuevo_centroide = [
                        sum(punto[j] for punto in puntos_cluster) / len(puntos_cluster)
                        for j in range(n_vars)
                    ]
                    nuevos_centroides.append(nuevo_centroide)
                else:
                    nuevos_centroides.append(centroides[cluster_id])

            # Verificar convergencia
            cambio = sum(
                math.sqrt(sum((nuevos_centroides[i][j] - centroides[i][j])**2 for j in range(n_vars)))
                for i in range(k)
            )

            centroides = nuevos_centroides

            if cambio < 0.0001:
                print(f"\n‚úì Convergencia alcanzada en iteraci√≥n {iteracion + 1}")
                break

        # Resultados
        print(f"\nüìä Distribuci√≥n de clusters:")
        for cluster_id in range(k):
            n_puntos = asignaciones.count(cluster_id)
            porcentaje = (n_puntos / n_obs) * 100
            print(f"   Cluster {cluster_id + 1}: {n_puntos} puntos ({porcentaje:.1f}%)")

        print(f"\nüéØ Centroides finales (valores normalizados):")
        for i, centroide in enumerate(centroides):
            print(f"\n   Cluster {i + 1}:")
            for j, param in enumerate(parametros):
                print(f"      {param}: {centroide[j]:.4f}")

        # Calcular inercia (suma de distancias cuadradas intra-cluster)
        inercia = 0
        for i, obs in enumerate(observaciones):
            cluster_id = asignaciones[i]
            dist_sq = sum((obs[j] - centroides[cluster_id][j])**2 for j in range(n_vars))
            inercia += dist_sq

        print(f"\nüìè Inercia total: {inercia:.4f}")
        print(f"   (Menor inercia indica clusters m√°s compactos)")

        return asignaciones, centroides

    def analisis_espacial(self):
        """Analiza patrones espaciales usando coordenadas geogr√°ficas"""
        print("\n" + "="*80)
        print("AN√ÅLISIS ESPACIAL")
        print("="*80)

        # Extraer coordenadas y TDS
        puntos = []
        for fila in self.cargador.datos_combinados:
            try:
                lat = float(fila.get('lat_gis', 0))
                lon = float(fila.get('long_gis', 0))
                tds = float(fila.get('TDS', 0))
                if lat != 0 and lon != 0 and tds > 0:
                    puntos.append((lat, lon, tds))
            except (ValueError, TypeError):
                pass

        print(f"\nüìç Puntos de muestreo con coordenadas: {len(puntos)}")

        # Calcular estad√≠sticas espaciales
        latitudes = [p[0] for p in puntos]
        longitudes = [p[1] for p in puntos]
        tds_valores = [p[2] for p in puntos]

        print(f"\nüó∫Ô∏è  Extensi√≥n geogr√°fica:")
        print(f"   Latitud:  {min(latitudes):.4f} a {max(latitudes):.4f}")
        print(f"   Longitud: {min(longitudes):.4f} a {max(longitudes):.4f}")

        # Dividir en cuadrantes
        lat_media = self.stats.media(latitudes)
        lon_media = self.stats.media(longitudes)

        cuadrantes = {
            'NE': [], 'NW': [], 'SE': [], 'SW': []
        }

        for lat, lon, tds in puntos:
            if lat >= lat_media and lon >= lon_media:
                cuadrantes['NE'].append(tds)
            elif lat >= lat_media and lon < lon_media:
                cuadrantes['NW'].append(tds)
            elif lat < lat_media and lon >= lon_media:
                cuadrantes['SE'].append(tds)
            else:
                cuadrantes['SW'].append(tds)

        print(f"\nüß≠ An√°lisis por cuadrantes (TDS promedio):")
        for cuadrante, valores in cuadrantes.items():
            if valores:
                promedio = self.stats.media(valores)
                n = len(valores)
                print(f"   {cuadrante}: {promedio:.2f} mg/L (n={n})")

        # Autocorrelaci√≥n espacial simplificada
        print(f"\nüìä Variabilidad espacial:")
        print(f"   Coef. variaci√≥n TDS: {self.stats.coeficiente_variacion(tds_valores):.2f}%")


# ============================================================================
# M√ìDULO 6: CIENCIA DE DATOS
# ============================================================================

class CienciaDatos:
    """Modelos predictivos, feature importance y validaci√≥n"""

    def __init__(self, cargador: CargadorDatos):
        self.cargador = cargador
        self.stats = EstadisticaManual()

    def preparar_datos_clasificacion(self):
        """Prepara datos para clasificaci√≥n de calidad de agua"""
        print("\n" + "="*80)
        print("PREPARACI√ìN DE DATOS PARA MODELADO")
        print("="*80)

        # Caracter√≠sticas y target
        features = ['pH', 'E.C', 'TDS', 'CO3', 'HCO3', 'Cl', 'Na', 'Ca', 'Mg', 'T.H', 'SAR']

        X = []
        y = []

        for fila in self.cargador.datos_combinados:
            try:
                # Extraer features
                fila_features = []
                valido = True
                for feature in features:
                    valor = float(fila.get(feature, 0))
                    if valor == 0:
                        valido = False
                        break
                    fila_features.append(valor)

                if valido:
                    clasificacion = fila.get('Classification', '')
                    if clasificacion:
                        X.append(fila_features)
                        y.append(clasificacion)
            except (ValueError, TypeError):
                pass

        print(f"\nüìä Dataset preparado:")
        print(f"   Muestras totales: {len(X)}")
        print(f"   Features: {len(features)}")
        print(f"   Clases √∫nicas: {len(set(y))}")

        # Distribuci√≥n de clases
        print(f"\nüìà Distribuci√≥n de clases:")
        clases_count = {}
        for clase in y:
            clases_count[clase] = clases_count.get(clase, 0) + 1

        for clase, count in sorted(clases_count.items(), key=lambda x: x[1], reverse=True):
            porcentaje = (count / len(y)) * 100
            print(f"   {clase}: {count} ({porcentaje:.1f}%)")

        return X, y, features

    def validacion_cruzada_manual(self, X: List[List[float]], y: List[str], k: int = 5):
        """Implementaci√≥n manual de validaci√≥n cruzada k-fold"""
        print(f"\n{'‚îÄ'*80}")
        print(f"VALIDACI√ìN CRUZADA {k}-FOLD")
        print(f"{'‚îÄ'*80}")

        n = len(X)
        fold_size = n // k

        print(f"\nüìä Configuraci√≥n:")
        print(f"   Total de muestras: {n}")
        print(f"   N√∫mero de folds: {k}")
        print(f"   Tama√±o de cada fold: ~{fold_size}")

        # Crear √≠ndices para cada fold
        indices = list(range(n))
        import random
        random.seed(42)
        random.shuffle(indices)

        folds = []
        for i in range(k):
            inicio = i * fold_size
            fin = inicio + fold_size if i < k - 1 else n
            folds.append(indices[inicio:fin])

        print(f"\n‚úì Folds creados exitosamente")
        for i, fold in enumerate(folds):
            print(f"   Fold {i+1}: {len(fold)} muestras")

        return folds

    def clasificador_naive_bayes_manual(self, X_train: List[List[float]], y_train: List[str],
                                       X_test: List[List[float]], y_test: List[str]):
        """
        Implementaci√≥n simplificada de Naive Bayes Gaussiano
        """
        print(f"\n{'‚îÄ'*80}")
        print("CLASIFICADOR NAIVE BAYES")
        print(f"{'‚îÄ'*80}")

        # Calcular probabilidades a priori y estad√≠sticas por clase
        clases = list(set(y_train))
        n_features = len(X_train[0])

        # Estad√≠sticas por clase
        stats_por_clase = {}
        for clase in clases:
            # Filtrar datos de esta clase
            X_clase = [X_train[i] for i in range(len(X_train)) if y_train[i] == clase]

            # Calcular media y desviaci√≥n est√°ndar para cada feature
            medias = []
            desvs = []
            for j in range(n_features):
                feature_valores = [x[j] for x in X_clase]
                medias.append(self.stats.media(feature_valores))
                desvs.append(self.stats.desviacion_estandar(feature_valores))

            stats_por_clase[clase] = {
                'prior': len(X_clase) / len(X_train),
                'medias': medias,
                'desvs': desvs
            }

        # Funci√≥n de densidad gaussiana
        def gaussian_pdf(x, media, desv):
            if desv == 0:
                return 1.0
            exponente = -((x - media) ** 2) / (2 * desv ** 2)
            return (1 / (desv * math.sqrt(2 * math.pi))) * math.exp(exponente)

        # Predecir
        predicciones = []
        for x in X_test:
            probabilidades = {}
            for clase in clases:
                # Probabilidad a priori
                prob = math.log(stats_por_clase[clase]['prior'])

                # Multiplicar probabilidades de cada feature (sumar en log)
                for j in range(n_features):
                    media = stats_por_clase[clase]['medias'][j]
                    desv = stats_por_clase[clase]['desvs'][j]
                    prob += math.log(gaussian_pdf(x[j], media, desv) + 1e-10)

                probabilidades[clase] = prob

            # Seleccionar clase con mayor probabilidad
            predicciones.append(max(probabilidades, key=probabilidades.get))

        # Calcular m√©tricas
        accuracy = sum(1 for i in range(len(y_test)) if predicciones[i] == y_test[i]) / len(y_test)

        print(f"\nüìä Resultados:")
        print(f"   Muestras de entrenamiento: {len(X_train)}")
        print(f"   Muestras de prueba: {len(X_test)}")
        print(f"   Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")

        # Matriz de confusi√≥n simplificada
        print(f"\nüìà Matriz de confusi√≥n (primeras 5 clases):")
        clases_top = sorted(set(y_test), key=lambda c: y_test.count(c), reverse=True)[:5]

        matriz = {c1: {c2: 0 for c2 in clases_top} for c1 in clases_top}
        for i in range(len(y_test)):
            if y_test[i] in clases_top and predicciones[i] in clases_top:
                matriz[y_test[i]][predicciones[i]] += 1

        print(f"\n{'Real/Pred':<12}", end="")
        for clase in clases_top:
            print(f"{clase:>8}", end="")
        print()
        print("‚îÄ" * (12 + 8 * len(clases_top)))

        for clase_real in clases_top:
            print(f"{clase_real:<12}", end="")
            for clase_pred in clases_top:
                print(f"{matriz[clase_real][clase_pred]:>8}", end="")
            print()

        return accuracy, predicciones

    def feature_importance_manual(self, X: List[List[float]], y: List[str],
                                  feature_names: List[str]):
        """
        Calcula importancia de features usando correlaci√≥n con el target
        """
        print(f"\n{'‚îÄ'*80}")
        print("IMPORTANCIA DE CARACTER√çSTICAS")
        print(f"{'‚îÄ'*80}")

        # Convertir clases a valores num√©ricos
        clases_unicas = sorted(set(y))
        y_numerico = [clases_unicas.index(clase) for clase in y]

        # Calcular correlaci√≥n de cada feature con el target
        importancias = []
        for j in range(len(feature_names)):
            feature_valores = [x[j] for x in X]
            corr = abs(self.stats.correlacion_pearson(feature_valores, y_numerico))
            importancias.append((feature_names[j], corr))

        # Ordenar por importancia
        importancias.sort(key=lambda x: x[1], reverse=True)

        print(f"\nüìä Ranking de caracter√≠sticas:")
        print(f"{'Caracter√≠stica':<15} {'Importancia':<12} {'Gr√°fico'}")
        print("‚îÄ" * 80)

        max_imp = importancias[0][1] if importancias else 1
        for i, (feature, imp) in enumerate(importancias):
            barra = '‚ñà' * int((imp / max_imp) * 40)
            print(f"{i+1}. {feature:<12} {imp:>10.4f}   {barra}")

        return importancias

    def analisis_predictivo_completo(self):
        """Ejecuta pipeline completo de ciencia de datos"""
        print("\n" + "="*80)
        print("AN√ÅLISIS PREDICTIVO COMPLETO")
        print("="*80)

        # Preparar datos
        X, y, features = self.preparar_datos_clasificacion()

        if len(X) < 100:
            print("\n‚ö†Ô∏è  Datos insuficientes para an√°lisis predictivo")
            return

        # Feature importance
        self.feature_importance_manual(X, y, features)

        # Dividir en train/test (80/20)
        n = len(X)
        n_train = int(n * 0.8)

        import random
        random.seed(42)
        indices = list(range(n))
        random.shuffle(indices)

        X_train = [X[i] for i in indices[:n_train]]
        y_train = [y[i] for i in indices[:n_train]]
        X_test = [X[i] for i in indices[n_train:]]
        y_test = [y[i] for i in indices[n_train:]]

        print(f"\nüìä Divisi√≥n de datos:")
        print(f"   Entrenamiento: {len(X_train)} ({len(X_train)/n*100:.1f}%)")
        print(f"   Prueba: {len(X_test)} ({len(X_test)/n*100:.1f}%)")

        # Entrenar y evaluar modelo
        accuracy, predicciones = self.clasificador_naive_bayes_manual(
            X_train, y_train, X_test, y_test
        )

        # M√©tricas por clase
        print(f"\nüìà M√©tricas por clase:")
        clases_unicas = sorted(set(y_test))

        for clase in clases_unicas[:5]:  # Top 5 clases
            tp = sum(1 for i in range(len(y_test)) if y_test[i] == clase and predicciones[i] == clase)
            fp = sum(1 for i in range(len(y_test)) if y_test[i] != clase and predicciones[i] == clase)
            fn = sum(1 for i in range(len(y_test)) if y_test[i] == clase and predicciones[i] != clase)

            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

            print(f"\n   Clase {clase}:")
            print(f"      Precision: {precision:.4f}")
            print(f"      Recall:    {recall:.4f}")
            print(f"      F1-Score:  {f1:.4f}")


# ============================================================================
# M√ìDULO 7: AN√ÅLISIS DE CALIDAD SEG√öN NORMATIVAS
# ============================================================================

class AnalisisCalidad:
    """Eval√∫a calidad del agua seg√∫n normativas y est√°ndares"""

    def __init__(self, cargador: CargadorDatos):
        self.cargador = cargador
        self.stats = EstadisticaManual()

    def evaluar_calidad_rsc(self):
        """Eval√∫a calidad seg√∫n RSC (Residual Sodium Carbonate)"""
        print("\n" + "="*80)
        print("EVALUACI√ìN DE CALIDAD SEG√öN RSC")
        print("="*80)

        rsc_valores = self.cargador.extraer_columna('RSC  meq  / L')

        if not rsc_valores:
            print("‚ö†Ô∏è  No hay datos de RSC disponibles")
            return

        # Clasificar seg√∫n RSC
        seguro = sum(1 for x in rsc_valores if x < 1.25)
        marginal = sum(1 for x in rsc_valores if 1.25 <= x <= 2.50)
        inadecuado = sum(1 for x in rsc_valores if x > 2.50)
        total = len(rsc_valores)

        print(f"\nüìä Clasificaci√≥n seg√∫n RSC:")
        print(f"   Seguro (< 1.25):        {seguro} ({seguro/total*100:.1f}%)")
        print(f"   Marginal (1.25-2.50):   {marginal} ({marginal/total*100:.1f}%)")
        print(f"   Inadecuado (> 2.50):    {inadecuado} ({inadecuado/total*100:.1f}%)")

        print(f"\nüìà Estad√≠sticas RSC:")
        print(f"   Media:    {self.stats.media(rsc_valores):.4f}")
        print(f"   Mediana:  {self.stats.mediana(rsc_valores):.4f}")
        print(f"   M√≠nimo:   {min(rsc_valores):.4f}")
        print(f"   M√°ximo:   {max(rsc_valores):.4f}")

    def evaluar_calidad_tds(self):
        """Eval√∫a calidad seg√∫n TDS para uso ganadero"""
        print("\n" + "="*80)
        print("EVALUACI√ìN DE CALIDAD SEG√öN TDS (Uso Ganadero)")
        print("="*80)

        tds_valores = self.cargador.extraer_columna('TDS')

        if not tds_valores:
            print("‚ö†Ô∏è  No hay datos de TDS disponibles")
            return

        # Clasificar seg√∫n TDS
        excelente = sum(1 for x in tds_valores if x < 1000)
        satisfactorio = sum(1 for x in tds_valores if 1000 <= x < 3000)
        limitado_aves = sum(1 for x in tds_valores if 3000 <= x < 5000)
        limitado = sum(1 for x in tds_valores if 5000 <= x < 7000)
        muy_limitado = sum(1 for x in tds_valores if 7000 <= x < 10000)
        no_recomendado = sum(1 for x in tds_valores if x >= 10000)
        total = len(tds_valores)

        print(f"\nüìä Clasificaci√≥n seg√∫n TDS (mg/L):")
        print(f"   Excelente (< 1000):           {excelente} ({excelente/total*100:.1f}%)")
        print(f"   Satisfactorio (1000-3000):    {satisfactorio} ({satisfactorio/total*100:.1f}%)")
        print(f"   Limitado aves (3000-5000):    {limitado_aves} ({limitado_aves/total*100:.1f}%)")
        print(f"   Limitado (5000-7000):         {limitado} ({limitado/total*100:.1f}%)")
        print(f"   Muy limitado (7000-10000):    {muy_limitado} ({muy_limitado/total*100:.1f}%)")
        print(f"   No recomendado (‚â• 10000):     {no_recomendado} ({no_recomendado/total*100:.1f}%)")

    def analisis_ph(self):
        """Analiza niveles de pH"""
        print("\n" + "="*80)
        print("AN√ÅLISIS DE pH")
        print("="*80)

        ph_valores = self.cargador.extraer_columna('pH')

        if not ph_valores:
            print("‚ö†Ô∏è  No hay datos de pH disponibles")
            return

        # Clasificar pH
        muy_acido = sum(1 for x in ph_valores if x < 6.5)
        neutro = sum(1 for x in ph_valores if 6.5 <= x <= 8.5)
        alcalino = sum(1 for x in ph_valores if x > 8.5)
        total = len(ph_valores)

        print(f"\nüìä Clasificaci√≥n de pH:")
        print(f"   √Åcido (< 6.5):      {muy_acido} ({muy_acido/total*100:.1f}%)")
        print(f"   Neutro (6.5-8.5):   {neutro} ({neutro/total*100:.1f}%)")
        print(f"   Alcalino (> 8.5):   {alcalino} ({alcalino/total*100:.1f}%)")

        print(f"\nüìà Estad√≠sticas pH:")
        print(f"   Media:    {self.stats.media(ph_valores):.2f}")
        print(f"   Mediana:  {self.stats.mediana(ph_valores):.2f}")
        print(f"   Rango:    {min(ph_valores):.2f} - {max(ph_valores):.2f}")


# ============================================================================
# M√ìDULO 8: GENERADOR DE REPORTES
# ============================================================================

class GeneradorReportes:
    """Genera reportes consolidados de an√°lisis"""

    def __init__(self, cargador: CargadorDatos):
        self.cargador = cargador

    def reporte_ejecutivo(self):
        """Genera un reporte ejecutivo consolidado"""
        print("\n" + "="*80)
        print("REPORTE EJECUTIVO - CALIDAD DE AGUA SUBTERR√ÅNEA")
        print("="*80)
        print("\nüìã Resumen de Hallazgos Principales\n")

        stats = EstadisticaManual()

        # 1. Cobertura del estudio
        total_muestras = len(self.cargador.datos_combinados)
        distritos = set(fila.get('district', '') for fila in self.cargador.datos_combinados)

        print("1Ô∏è‚É£  COBERTURA DEL ESTUDIO")
        print(f"   ‚Ä¢ Total de muestras analizadas: {total_muestras}")
        print(f"   ‚Ä¢ Distritos cubiertos: {len(distritos)}")
        print(f"   ‚Ä¢ Per√≠odo: 2018-2020 (post-monz√≥n)")

        # 2. Calidad general
        clasificaciones = {}
        for fila in self.cargador.datos_combinados:
            clasif = fila.get('Classification', 'Desconocido')
            clasificaciones[clasif] = clasificaciones.get(clasif, 0) + 1

        print("\n2Ô∏è‚É£  CALIDAD GENERAL DEL AGUA")
        top_3_clasif = sorted(clasificaciones.items(), key=lambda x: x[1], reverse=True)[:3]
        for i, (clasif, count) in enumerate(top_3_clasif, 1):
            porcentaje = (count / total_muestras) * 100
            print(f"   {i}. {clasif}: {porcentaje:.1f}% de las muestras")

        # 3. Par√°metros cr√≠ticos
        tds_valores = self.cargador.extraer_columna('TDS')
        ph_valores = self.cargador.extraer_columna('pH')

        print("\n3Ô∏è‚É£  PAR√ÅMETROS CR√çTICOS")
        if tds_valores:
            tds_promedio = stats.media(tds_valores)
            tds_alto = sum(1 for x in tds_valores if x > 3000)
            print(f"   ‚Ä¢ TDS promedio: {tds_promedio:.0f} mg/L")
            print(f"   ‚Ä¢ Muestras con TDS alto (>3000): {tds_alto/len(tds_valores)*100:.1f}%")

        if ph_valores:
            ph_promedio = stats.media(ph_valores)
            ph_alcalino = sum(1 for x in ph_valores if x > 8.5)
            print(f"   ‚Ä¢ pH promedio: {ph_promedio:.2f}")
            print(f"   ‚Ä¢ Muestras alcalinas (pH>8.5): {ph_alcalino/len(ph_valores)*100:.1f}%")

        # 4. Recomendaciones
        print("\n4Ô∏è‚É£  RECOMENDACIONES")
        print("   ‚Ä¢ Monitoreo continuo de zonas con alta salinidad")
        print("   ‚Ä¢ Implementar pr√°cticas de manejo seg√∫n clasificaci√≥n")
        print("   ‚Ä¢ Considerar tratamientos para zonas C4 (muy alta salinidad)")
        print("   ‚Ä¢ Evaluar uso de enmiendas (yeso) en zonas con alto SAR")

        print("\n" + "="*80)


# ============================================================================
# FUNCI√ìN PRINCIPAL
# ============================================================================

def main():
    """Funci√≥n principal que ejecuta todos los an√°lisis"""

    print("\n" + "‚ñà"*80)
    print("‚ñà" + " "*78 + "‚ñà")
    print("‚ñà" + " "*20 + "AN√ÅLISIS DE CALIDAD DE AGUA SUBTERR√ÅNEA" + " "*19 + "‚ñà")
    print("‚ñà" + " "*25 + "Sistema Profesional de An√°lisis" + " "*22 + "‚ñà")
    print("‚ñà" + " "*78 + "‚ñà")
    print("‚ñà"*80)

    # Cargar datos
    print("\nüîÑ Cargando datos...")
    cargador = CargadorDatos("samples")
    cargador.cargar_archivos_csv()

    if not cargador.datos_combinados:
        print("‚ùå No se pudieron cargar los datos. Verifica la ruta.")
        return

    # Men√∫ interactivo
    while True:
        print("\n" + "="*80)
        print("MEN√ö PRINCIPAL")
        print("="*80)
        print("\nüìä AN√ÅLISIS B√ÅSICO")
        print("   1. Resumen general del dataset")
        print("   2. Estad√≠sticas descriptivas por par√°metro")
        print("   3. An√°lisis de calidad por distrito")

        print("\nüìà AN√ÅLISIS MEDIO")
        print("   4. Matriz de correlaci√≥n")
        print("   5. Detecci√≥n de outliers")
        print("   6. An√°lisis temporal (2018-2020)")
        print("   7. An√°lisis de distribuci√≥n")

        print("\nüî¨ AN√ÅLISIS AVANZADO")
        print("   8. PCA (Componentes Principales)")
        print("   9. Clustering K-Means")
        print("   10. An√°lisis espacial")

        print("\nü§ñ CIENCIA DE DATOS")
        print("   11. An√°lisis predictivo completo")
        print("   12. Feature importance")

        print("\nüíß EVALUACI√ìN DE CALIDAD")
        print("   13. Evaluaci√≥n seg√∫n RSC")
        print("   14. Evaluaci√≥n seg√∫n TDS")
        print("   15. An√°lisis de pH")

        print("\nüìã REPORTES")
        print("   16. Reporte ejecutivo")
        print("   17. An√°lisis completo (todos los m√≥dulos)")

        print("\n   0. Salir")

        try:
            opcion = input("\nüëâ Selecciona una opci√≥n: ").strip()

            if opcion == "0":
                print("\n‚úÖ An√°lisis finalizado. ¬°Hasta pronto!")
                break

            elif opcion == "1":
                analisis_basico = AnalisisBasico(cargador)
                analisis_basico.resumen_general()

            elif opcion == "2":
                parametros = ['pH', 'E.C', 'TDS', 'T.H', 'SAR', 'Cl', 'Na']
                analisis_basico = AnalisisBasico(cargador)
                for param in parametros:
                    analisis_basico.estadisticas_descriptivas(param)
                    input("\nPresiona Enter para continuar...")

            elif opcion == "3":
                analisis_basico = AnalisisBasico(cargador)
                analisis_basico.calidad_por_distrito()

            elif opcion == "4":
                analisis_medio = AnalisisMedio(cargador)
                analisis_medio.matriz_correlacion()

            elif opcion == "5":
                analisis_medio = AnalisisMedio(cargador)
                parametros = ['TDS', 'E.C', 'T.H', 'SAR']
                for param in parametros:
                    analisis_medio.detectar_outliers_iqr(param)

            elif opcion == "6":
                analisis_medio = AnalisisMedio(cargador)
                analisis_medio.analisis_temporal()

            elif opcion == "7":
                analisis_medio = AnalisisMedio(cargador)
                parametros = ['TDS', 'pH', 'SAR']
                for param in parametros:
                    analisis_medio.analisis_distribucion(param)

            elif opcion == "8":
                analisis_avanzado = AnalisisAvanzado(cargador)
                analisis_avanzado.pca_manual()

            elif opcion == "9":
                analisis_avanzado = AnalisisAvanzado(cargador)
                analisis_avanzado.clustering_kmeans_manual(k=4)

            elif opcion == "10":
                analisis_avanzado = AnalisisAvanzado(cargador)
                analisis_avanzado.analisis_espacial()

            elif opcion == "11":
                ciencia_datos = CienciaDatos(cargador)
                ciencia_datos.analisis_predictivo_completo()

            elif opcion == "12":
                ciencia_datos = CienciaDatos(cargador)
                X, y, features = ciencia_datos.preparar_datos_clasificacion()
                ciencia_datos.feature_importance_manual(X, y, features)

            elif opcion == "13":
                analisis_calidad = AnalisisCalidad(cargador)
                analisis_calidad.evaluar_calidad_rsc()

            elif opcion == "14":
                analisis_calidad = AnalisisCalidad(cargador)
                analisis_calidad.evaluar_calidad_tds()

            elif opcion == "15":
                analisis_calidad = AnalisisCalidad(cargador)
                analisis_calidad.analisis_ph()

            elif opcion == "16":
                generador = GeneradorReportes(cargador)
                generador.reporte_ejecutivo()

            elif opcion == "17":
                print("\nüöÄ Ejecutando an√°lisis completo...")

                # B√°sico
                analisis_basico = AnalisisBasico(cargador)
                analisis_basico.resumen_general()

                # Medio
                analisis_medio = AnalisisMedio(cargador)
                analisis_medio.matriz_correlacion()
                analisis_medio.analisis_temporal()

                # Avanzado
                analisis_avanzado = AnalisisAvanzado(cargador)
                analisis_avanzado.pca_manual()
                analisis_avanzado.clustering_kmeans_manual(k=4)

                # Calidad
                analisis_calidad = AnalisisCalidad(cargador)
                analisis_calidad.evaluar_calidad_rsc()
                analisis_calidad.evaluar_calidad_tds()

                # Reporte
                generador = GeneradorReportes(cargador)
                generador.reporte_ejecutivo()

                print("\n‚úÖ An√°lisis completo finalizado")

            else:
                print("\n‚ö†Ô∏è  Opci√≥n no v√°lida. Intenta de nuevo.")

            input("\n‚è∏Ô∏è  Presiona Enter para volver al men√∫...")

        except KeyboardInterrupt:
            print("\n\n‚úÖ An√°lisis interrumpido. ¬°Hasta pronto!")
            break
        except Exception as e:
            print(f"\n‚ùå Error: {e}")
            input("\nPresiona Enter para continuar...")


if __name__ == "__main__":
    main()


